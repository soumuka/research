{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6ee3957",
   "metadata": {},
   "source": [
    "# 案例：当当网 Python 类图书销售数据分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f921a7a",
   "metadata": {},
   "source": [
    "## 背景\n",
    "\n",
    "我想写一本有关 Python 应用的书。目前我有很多想法，拿不定主意。比如，\n",
    "\n",
    "- 目标读者是谁？经管类博士生，还是中小学生？\n",
    "- 书的内容是什么？是 Python 基础知识，还是 Python 数据分析？亦或是机器学习？\n",
    "- 书的形式是什么？是电子书，还是纸质书？亦或是两者都有？\n",
    "- 书的价格是多少？是 50 元，还是 100 元？亦或是 200 元？\n",
    "- 找哪家出版社？\n",
    "\n",
    "在不了解这些信息的情况下，贸然画一年的时间写一本书是一个非常冒险的决定。为了降低风险，我决定先做一些市场调研，看看读者对 Python 书籍的需求。\n",
    "\n",
    "我先通过百度搜索和 Google 搜索，了解到当当网是中国最大的图书销售网站之一，拥有丰富的图书数据。我决定从当当网获取一些 Python 类图书的销售数据，进行分析，看看读者对 Python 书籍的需求。\n",
    "\n",
    "问题来了，我只有一些非常基础的 Python 知识 (大体上限于能对着课本或帮助文档提供的实例进行一些微小的修改，然后运行)。而且，我目前掌握的 Python 知识基本上进局限于回归分析。对于网络爬虫、数据分析、数据可视化等知识，我几乎一无所知。\n",
    "\n",
    "我听说 ChatGPT, DeepSeek 等 AI 工具可以帮助我完成一些复杂的任务，比如网络爬虫、数据分析、数据可视化等。我决定试试这些工具，看看它们能否帮助我完成我的市场调研。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98a81c1",
   "metadata": {},
   "source": [
    "\n",
    "于是，我写一个提示词，发给了 ChatGPT：\n",
    "\n",
    "> [与 ChatGPT 的完整对话](https://chatgpt.com/share/6825d453-524c-8005-b82c-a9530cf983ff)\n",
    "\n",
    "\n",
    "::: {.callout-tip}\n",
    "### 提示词\n",
    "\n",
    "```md\n",
    "- 目的：从当当网获取Python相关书籍的销售量信息，最终输出一份市场调研报告。\n",
    "- 语言：Python\n",
    "- 网站：[https://search.dangdang.com/](https://search.dangdang.com/)\n",
    "- 关键词：'python'\n",
    "- 排序关键词：'销量'\n",
    "- 排序方式：从高到低\n",
    "- 信息条数：前 20 条\n",
    "- 目前搜索结果页面URL：[https://search.dangdang.com/?key=python\\&act=input\\&sort\\_type=sort\\_sale\\_amt\\_desc#J\\_tab](https://search.dangdang.com/?key=python&act=input&sort_type=sort_sale_amt_desc#J_tab)\n",
    "\n",
    "- 预期输出： \n",
    "  - 书名，作者，年份，出版社，评论数，原价、折后价\n",
    "\n",
    "以上是我目前想到的。\n",
    "请帮我做一个全面的规划，包括分析目标、收集那些变量，分析流程，以及最终的报告形式、核心内容等。\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3186ba",
   "metadata": {},
   "source": [
    "以下是 ChatGPT 的回复："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f1179e",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "### AI 的回复\n",
    "\n",
    "好的，以下是一份较为系统的规划方案，适用于以 Python 编写程序从当当网采集“Python”相关书籍的销售量数据，并撰写一份结构完整的市场调研报告。\n",
    "\n",
    "---\n",
    "\n",
    "# Python 相关图书市场调研项目规划\n",
    "\n",
    "## 一、分析目标\n",
    "\n",
    "* **核心问题**：当前在当当网上热销的 Python 图书有哪些？主要出版时间集中在哪些年份？哪些出版社主导了市场？\n",
    "* **业务用途**：\n",
    "\n",
    "  * 为出版商、培训机构、书店提供选书参考；\n",
    "  * 了解当前市场偏好（入门/进阶、编程/数据分析/人工智能）；\n",
    "  * 为课程教材选择提供数据支持。\n",
    "\n",
    "---\n",
    "\n",
    "## 二、数据采集计划\n",
    "\n",
    "### 1. 数据来源\n",
    "\n",
    "* 网址：[https://search.dangdang.com/?key=python\\&act=input\\&sort\\_type=sort\\_sale\\_amt\\_desc#J\\_tab](https://search.dangdang.com/?key=python&act=input&sort_type=sort_sale_amt_desc#J_tab)\n",
    "* 请求类型：GET\n",
    "* 页数限制：目前仅采集排序后**前 20 本书**\n",
    "* 排序方式：**按销量从高到低**\n",
    "\n",
    "### 2. 待采集字段（建议）\n",
    "\n",
    "| 字段名       | 说明               |\n",
    "| --------- | ---------------- |\n",
    "| `书名`      | 完整书名             |\n",
    "| `作者`      | 主作者及其他合著者        |\n",
    "| `出版社`     | 出版机构             |\n",
    "| `出版时间`    | 年份或具体日期          |\n",
    "| `原价`      | 划线价              |\n",
    "| `折后价`     | 实际售价             |\n",
    "| `评论数`     | 用户评论数，反映活跃度      |\n",
    "| `星级评分`    | 若有星级则采集          |\n",
    "| `封面图链接`   | 便于后续可视化展示        |\n",
    "| `图书详情页链接` | 为后续扩展字段或人工校验提供入口 |\n",
    "\n",
    "---\n",
    "\n",
    "## 三、分析流程\n",
    "\n",
    "### Step 1：数据采集（Python 编程）\n",
    "\n",
    "* 使用库：\n",
    "\n",
    "  * `requests` 模拟访问\n",
    "  * `BeautifulSoup` 解析 HTML\n",
    "  * `re` 或 `lxml` 辅助提取字段\n",
    "* 反爬措施应对：\n",
    "\n",
    "  * 合理设置 `headers`（如模拟浏览器 UA）\n",
    "  * 增加 `time.sleep()` 随机延迟\n",
    "  * 如遇 JavaScript 动态加载，可考虑 `selenium`\n",
    "\n",
    "### Step 2：数据清洗与规范化\n",
    "\n",
    "* 作者、出版社等字段统一格式\n",
    "* 出版时间转为 `datetime`\n",
    "* 价格字段转换为 float\n",
    "* 评论数转换为整数（去除“条评论”字样）\n",
    "\n",
    "### Step 3：数据分析\n",
    "\n",
    "#### 3.1 描述性统计\n",
    "\n",
    "* 平均价格、评论数中位数\n",
    "* 出版年份分布（近几年为主）\n",
    "* 高频作者、出版社统计\n",
    "\n",
    "#### 3.2 分类分析\n",
    "\n",
    "* 入门类 vs 进阶类\n",
    "* 数据分析 vs Web 编程 vs 机器学习\n",
    "* 是否为教材或考试参考书\n",
    "\n",
    "#### 3.3 排行榜可视化\n",
    "\n",
    "* 前 10 图书销量/评论/价格对比柱状图\n",
    "* 出版时间折线图\n",
    "* 价格 vs 评论数散点图\n",
    "\n",
    "---\n",
    "\n",
    "## 四、报告输出格式\n",
    "\n",
    "### 1. 技术报告形式（推荐）\n",
    "\n",
    "* **格式**：Markdown / Quarto / PDF（可由 Jupyter Notebook 或 Quarto 生成）\n",
    "* **结构建议**：\n",
    "\n",
    "```markdown\n",
    "# Python 图书销售市场调研报告（当当网）\n",
    "\n",
    "## 1. 项目背景与目标\n",
    "## 2. 数据采集与字段说明\n",
    "## 3. 市场总体概况\n",
    "   - 销售 Top20 图书一览\n",
    "   - 平均价格、评分、评论数等统计\n",
    "## 4. 出版特征分析\n",
    "   - 出版社分布、出版时间分布\n",
    "   - 作者贡献度分析\n",
    "## 5. 图书类型对比分析\n",
    "   - 入门、进阶分布\n",
    "   - 专业方向分布\n",
    "## 6. 结论与建议\n",
    "   - 当前趋势总结\n",
    "   - 出版或选书建议\n",
    "```\n",
    "\n",
    "### 2. 附录部分\n",
    "\n",
    "* 原始数据表格（20 本书）\n",
    "* 数据采集代码（附说明）\n",
    "* 图形可视化汇总图（Matplotlib / Seaborn / Plotly）\n",
    "\n",
    "---\n",
    "\n",
    "## 五、可扩展方向（可选）\n",
    "\n",
    "* 同步采集京东、淘宝图书频道以对比\n",
    "* 分析定价策略（原价 vs 折扣价规律）\n",
    "* 抽取关键词构建词云图\n",
    "* 构建图书推荐系统雏形\n",
    "\n",
    "---\n",
    "\n",
    "如你同意，我可以继续为你编写：\n",
    "\n",
    "1. Python 抓取前 20 条当当网图书数据的爬虫脚本；\n",
    "2. 可视化分析和 Markdown 报告生成模板；\n",
    "3. 教学型讲义或课程材料用版本。\n",
    "\n",
    "是否现在开始写代码部分？是否使用 `requests + BeautifulSoup`，还是你希望使用 `selenium` 模拟浏览器？\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f2b363",
   "metadata": {},
   "source": [
    "## 爬取数据\n",
    "\n",
    "我们让 ChatGPT 执行第一步：\n",
    "\n",
    "**Step 1：使用 Python 抓取当当网「Python」相关图书销量前 20 名信息** 的完整采集代码。\n",
    "\n",
    "### 技术选择说明\n",
    "\n",
    "* **目标网址**：[https://search.dangdang.com/?key=python\\&sort\\_type=sort\\_sale\\_amt\\_desc](https://search.dangdang.com/?key=python&sort_type=sort_sale_amt_desc)\n",
    "* **方案**：采用 `requests` + `BeautifulSoup` 进行静态页面解析（当当网图书搜索结果页大部分信息在 HTML 中，JS 渲染较少）\n",
    "* **爬取字段**：\n",
    "\n",
    "  * 书名\n",
    "  * 作者\n",
    "  * 出版社\n",
    "  * 出版时间\n",
    "  * 原价\n",
    "  * 折后价\n",
    "  * 评论数\n",
    "  * 商品详情页链接\n",
    "\n",
    "\n",
    "### Python 代码\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb44228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Github\\\\dslian\\\\cases\\\\web_dangdang_book'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置项目路径\n",
    "#   [./data]: 存储数据文件\n",
    "#   [./output]: 存储输出文件\n",
    "\n",
    "\n",
    "#---------------- 项目路径，酌情修改 -------------------\n",
    "#\n",
    "path = r'D:\\Github\\dslian\\cases\\web_dangdang_book' \n",
    "#\n",
    "#------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import sys\n",
    "path_data = os.path.join(path, 'data')\n",
    "path_output = os.path.join(path, 'output')\n",
    "\n",
    "os.chdir(path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469406f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已成功下载 60 条数据，点击 [file://d:\\Github\\dslian\\cases\\web_dangdang_book\\data\\dangdang_python_books_top20.csv] 查看 dangdang_python_books_top20.csv 文件\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# 设置目标搜索 URL（销量降序排序）\n",
    "url = \"https://search.dangdang.com/?key=python&sort_type=sort_sale_amt_desc\"\n",
    "\n",
    "# 设置请求头，模拟浏览器访问\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \\\n",
    "                   (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# 发送请求并获取页面内容\n",
    "response = requests.get(url, headers=headers)\n",
    "response.encoding = \"gb2312\"\n",
    "\n",
    "# 使用 BeautifulSoup 解析 HTML 内容\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# 所有图书的信息在 ul.bigimg li 中\n",
    "book_list = soup.select(\"ul.bigimg > li\")\n",
    "\n",
    "# 用于保存每本书的信息\n",
    "books_data = []\n",
    "\n",
    "# 遍历每本书的条目，提取信息\n",
    "for item in book_list:\n",
    "    try:\n",
    "        title_tag = item.select_one(\"a[name='itemlist-title']\")\n",
    "        title = title_tag.get(\"title\").strip() if title_tag else \"\"\n",
    "        link = title_tag.get(\"href\") if title_tag else \"\"\n",
    "\n",
    "        author_tag = item.select_one(\"p.name a\")\n",
    "        author = author_tag.text.strip() if author_tag else \"\"\n",
    "\n",
    "        pub_info_tag = item.select_one(\"p.search_book_author\")\n",
    "        pub_info = pub_info_tag.text.strip() if pub_info_tag else \"\"\n",
    "        pub_info_parts = pub_info.split(\"\\xa0\\xa0\")\n",
    "\n",
    "        publisher = pub_info_parts[1].strip() if len(pub_info_parts) > 1 else \"\"\n",
    "        pubdate = pub_info_parts[2].strip() if len(pub_info_parts) > 2 else \"\"\n",
    "\n",
    "        comment_tag = item.select_one(\"p.search_star_line a\")\n",
    "        comment = comment_tag.text.strip() if comment_tag else \"\"\n",
    "\n",
    "        price_tag = item.select_one(\"p.price\")\n",
    "        orig_price_tag = price_tag.select_one(\"span.search_pre_price\") if price_tag else None\n",
    "        disc_price_tag = price_tag.select_one(\"span.search_now_price\") if price_tag else None\n",
    "        orig_price = orig_price_tag.text.strip(\"¥\") if orig_price_tag else \"\"\n",
    "        disc_price = disc_price_tag.text.strip(\"¥\") if disc_price_tag else \"\"\n",
    "\n",
    "        books_data.append({\n",
    "            \"书名\": title,\n",
    "            \"作者\": author,\n",
    "            \"出版社\": publisher,\n",
    "            \"出版时间\": pubdate,\n",
    "            \"原价\": orig_price,\n",
    "            \"折后价\": disc_price,\n",
    "            \"评论数\": comment,\n",
    "            \"详情页链接\": link\n",
    "        })\n",
    "\n",
    "        time.sleep(0.5)  # 加入短暂停顿防止访问过快\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"解析失败：{e}\")\n",
    "        continue\n",
    "\n",
    "# 转换为 DataFrame\n",
    "df_books = pd.DataFrame(books_data)\n",
    "\n",
    "# 确保保存路径存在\n",
    "output_path = \"data\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "output_file = os.path.join(output_path, \"dangdang_python_books_top20.csv\")\n",
    "\n",
    "# 保存为 CSV 文件\n",
    "df_books.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# 打印成功信息\n",
    "print(f\"已成功下载 {len(df_books)} 条数据，\n",
    "        点击 [file://{os.path.abspath(output_file)}] \n",
    "        查看 dangdang_python_books_top20.csv 文件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8fce22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已成功下载 60 条数据，点击 [file://d:\\Github\\dslian\\cases\\web_dangdang_book\\data\\dangdang_python_books_cleaned.csv] 查看 dangdang_python_books_cleaned.csv 文件\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "url = \"https://search.dangdang.com/?key=python&sort_type=sort_sale_amt_desc\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \\\n",
    "                   (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response.encoding = \"gb2312\"\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "book_list = soup.select(\"ul.bigimg > li\")\n",
    "\n",
    "books_data = []\n",
    "\n",
    "for item in book_list:\n",
    "    try:\n",
    "        # 1. 主标题和简介\n",
    "        title_tag = item.select_one(\"a[name='itemlist-title']\")\n",
    "        full_title = title_tag.get(\"title\").strip() if title_tag else \"\"\n",
    "        if \"：\" in full_title:\n",
    "            title, brief = full_title.split(\"：\", 1)\n",
    "        elif \"（\" in full_title:\n",
    "            title, brief = full_title.split(\"（\", 1)\n",
    "            brief = \"（\" + brief\n",
    "        else:\n",
    "            title, brief = full_title, \"\"\n",
    "\n",
    "        # 2. 详情页链接\n",
    "        link = title_tag.get(\"href\") if title_tag else \"\"\n",
    "\n",
    "        # 3. 作者 / 出版社 / 出版时间\n",
    "        pub_info_tag = item.select_one(\"p.search_book_author\")\n",
    "        pub_info_parts = pub_info_tag.text.strip().split(\"\\xa0\\xa0\") if pub_info_tag else []\n",
    "        author = pub_info_parts[0].replace(\"作者\", \"\").strip() if len(pub_info_parts) > 0 else \"\"\n",
    "        publisher = pub_info_parts[1].strip() if len(pub_info_parts) > 1 else \"\"\n",
    "        pubdate = pub_info_parts[2].strip() if len(pub_info_parts) > 2 else \"\"\n",
    "\n",
    "        # 4. 评论数\n",
    "        comment_tag = item.select_one(\"p.search_star_line a\")\n",
    "        comment = comment_tag.text.strip() if comment_tag else \"\"\n",
    "\n",
    "        # 5. 价格\n",
    "        price_tag = item.select_one(\"p.price\")\n",
    "        orig_price_tag = price_tag.select_one(\"span.search_pre_price\") if price_tag else None\n",
    "        disc_price_tag = price_tag.select_one(\"span.search_now_price\") if price_tag else None\n",
    "        orig_price = orig_price_tag.text.strip(\"¥\") if orig_price_tag else \"\"\n",
    "        disc_price = disc_price_tag.text.strip(\"¥\") if disc_price_tag else \"\"\n",
    "\n",
    "        books_data.append({\n",
    "            \"书名\": title,\n",
    "            \"简介\": brief,\n",
    "            \"作者\": author,\n",
    "            \"出版社\": publisher,\n",
    "            \"出版时间\": pubdate,\n",
    "            \"原价\": orig_price,\n",
    "            \"折后价\": disc_price,\n",
    "            \"评论数\": comment,\n",
    "            \"详情页链接\": link\n",
    "        })\n",
    "\n",
    "        time.sleep(0.5)  # 加入短暂停顿防止访问过快\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"解析失败：{e}\")\n",
    "        continue\n",
    "\n",
    "df_books = pd.DataFrame(books_data)\n",
    "\n",
    "output_path = \"data\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "output_file = os.path.join(output_path, \"dangdang_python_books_cleaned.csv\")\n",
    "df_books.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"已成功下载 {len(df_books)} 条数据，点击 [file://{os.path.abspath(output_file)}] 查看 dangdang_python_books_cleaned.csv 文件\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16d7917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['书名', '简介', '作者', '出版社', '出版时间', '原价', '折后价', '评论数', '详情页链接'], dtype='object')\n",
      "                                                  书名  \\\n",
      "0                                     Python编程三剑客第3版   \n",
      "1                                      小学生Python创意编程   \n",
      "2  Python编程从入门到实践 第3版 Python编程入门经典，自学利器，数据分析、网络爬虫...   \n",
      "\n",
      "                                                  简介  \\\n",
      "0          Python编程从入门到实践第3版+快速上手第2版+极客项目编程（当当套装共3册）   \n",
      "1  （视频教学版） 本书按照入门开发者的思维方式编写，非常适合孩子学习Python编程的基础知识...   \n",
      "2                                                NaN   \n",
      "\n",
      "                                                  作者  出版社  出版时间     原价   折后价  \\\n",
      "0                                            加入购物车收藏  NaN   NaN  267.8  21.6   \n",
      "1              刘凤飞 /2024-01-01  /清华大学出版社加入购物车购买电子书收藏  NaN   NaN   89.0  45.2   \n",
      "2  [美]埃里克・马瑟斯（Eric Matthes） /2023-05-01  /人民邮电出版社...  NaN   NaN  109.8  69.8   \n",
      "\n",
      "         评论数                                    详情页链接  \n",
      "0  124999条评论  //product.dangdang.com/12100010244.html  \n",
      "1    7157条评论     //product.dangdang.com/29666296.html  \n",
      "2   19970条评论     //product.dangdang.com/29564789.html  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60 entries, 0 to 59\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   书名      60 non-null     object \n",
      " 1   简介      29 non-null     object \n",
      " 2   作者      60 non-null     object \n",
      " 3   出版社     0 non-null      float64\n",
      " 4   出版时间    0 non-null      float64\n",
      " 5   原价      57 non-null     float64\n",
      " 6   折后价     60 non-null     float64\n",
      " 7   评论数     60 non-null     object \n",
      " 8   详情页链接   60 non-null     object \n",
      "dtypes: float64(4), object(5)\n",
      "memory usage: 4.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 读入本地数据\n",
    "df_books = pd.read_csv(r\"data\\dangdang_python_books_cleaned.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "# 展示前几行结果\n",
    "print(df_books.columns)\n",
    "print(df_books.head(3))\n",
    "print(df_books.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48317b54",
   "metadata": {},
   "source": [
    "## 后续\n",
    "\n",
    "我花了 30 分钟做到目前的样子，基本上搞懂了使用 Copilot 编写 Python 代码实现爬虫的流程。\n",
    "\n",
    "刚好当时在教授「数据分析与 Python 应用」的课程，我索性把这个案例作为课堂作业，要求学生们完成。\n",
    "\n",
    "- 作业要求：[T1-当当网Python类图书销售分析](https://github.com/arlionn/ds/blob/main/homework/Topics/T1-%E5%BD%93%E5%BD%93%E7%BD%91Python%E7%B1%BB%E5%9B%BE%E4%B9%A6%E9%94%80%E5%94%AE%E5%88%86%E6%9E%90.md)\n",
    "- 学生提交的 Jupyter Notebook：\n",
    "  - [当当网-G7-01：爬虫和数据清洗](https://book.lianxh.cn/ds/homework/pre/Dangdang_G7_01_data_clean.html)\n",
    "  - [当当网-G7-02：数据分析](https://book.lianxh.cn/ds/homework/pre/Dangdang_G7_02_data_analysis.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
