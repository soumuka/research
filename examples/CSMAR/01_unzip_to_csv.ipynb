{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8254e2e",
   "metadata": {},
   "source": [
    "# CSMAR 数据处理\n",
    "\n",
    "CSMAR (China Stock Market & Accounting Research) 是一个提供中国上市公司数据的数据库。本文将介绍如何使用 CSMAR 数据库获取上市公司基本信息和财务资料，并经过合并、清洗等处理，得到清洁数据。\n",
    "\n",
    "\n",
    "## 从 CAMAR 数据库下载 Excel 数据文件\n",
    "\n",
    "::: {.callout-note}\n",
    "### `.csv` 优于 `.xlsx`\n",
    "\n",
    "我此前对 Python 处理数据的机制了解不足，导致我最初下载的都是 `.xlsx` 格式的数据。虽然这种 Excel 格式的数据可以使用 `pandas` 读取，但非常耗时 (一份包含 8w 行观察值的资产负债表大概需要 50s)。相比之下，`.csv` 格式的数据读取速度更快，通常只需要几秒钟。\n",
    " \n",
    "因此，大家从 CSMAR 数据库下载数据时，建议选择 `.csv` 格式，而不是 `.xlsx` 格式。\n",
    ":::\n",
    "\n",
    "\n",
    "### 数据下载页面\n",
    "\n",
    "- 网址：<https://data.csmar.com/>\n",
    "- 登录：中大 IP 地址范围内自动登录 (机构账号)\n",
    "\n",
    "<img style=\"width: 400px\" src=\"https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250528000207.png\">\n",
    "\n",
    "主要有两种查询方案：\n",
    "\n",
    "- **单表查询**：直接查询某一张表格的数据。\n",
    "- **多表查询**：可以跨表查询，形成一个新的表格。\n",
    "\n",
    "两种模式下的查询流程大致相同：选择子库 >> 选择时间范围 >> 选择代码范围 >> 选择字段范围 >> 下载数据。\n",
    "\n",
    "建议尽量选择 `.csv` 或 `.txt` 格式下载数据，因为这两种格式的数据读取速度更快。\n",
    "\n",
    "\n",
    "下载后的文件通常为 **.zip** 格式，解压后会得到两份文件：\n",
    "- `FileName.csv`: 数据文件\n",
    "- `FileName[DES][xlsx].txt`: 变量说明文件\n",
    "\n",
    "数据库说明书：每个子库的右上角都会显示「**[数据库说明书](https://data.csmar.com/lib/pdfjs/web/viewer.html?file=group1%2FM00%2F3F%2FF2%2FCuIKV2c8MBmASlKhABdnboBfW5s152.pdf&fname=%E8%B4%A2%E5%8A%A1%E6%8A%A5%E8%A1%A8%20%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%B4%E6%98%8E%E4%B9%A6)**」，点击后可下载 PDF 格式的说明书，里面包含了该子库的所有表格、字段的详细信息。\n",
    "\n",
    "<img style=\"width: 650px\" src=\"https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250528001925.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5d19ce3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory: d:\\Github\\ds_data\\data\\CSMAR\n"
     ]
    }
   ],
   "source": [
    "# 文件路径设定{tag}\n",
    "# Note：进行后续分析之前，请先执行本 Cell 中的代码，以确保所有路径正确设置。\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 打开 .ipynb 文件的路径记为当前工作目录\n",
    "#path = os.getcwd()\n",
    "path = r'D:\\Github\\ds_data\\data\\CSMAR'    # 替换为你的实际路径\n",
    "os.chdir(path)  # 切换工作目录\n",
    "print('Working Directory:', os.getcwd())\n",
    "\n",
    "\n",
    "# Folders \n",
    "zip_folder = os.path.join(path, 'data_raw_zip')       # 原始压缩包存放目录\n",
    "extract_folder = os.path.join(path, 'data_raw')       # 解压后的数据存放目录\n",
    "data_clean_folder = os.path.join(path, 'data_clean')  # 清洗后的数据存放目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b6be3b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSMAR常用变量-2000-2024.zip\n",
      "上市公司基本信息变更表2000-2024.zip\n",
      "上市公司基本信息年度表.zip\n",
      "利润表-现金流量表-2000-2010.zip\n",
      "利润表-现金流量表-2011-2024.zip\n",
      "资产负债表-2000-2010.zip\n",
      "资产负债表-2011-2024.zip\n"
     ]
    }
   ],
   "source": [
    "# 列示 'data_raw_zip' 文件夹中的所有文件\n",
    "for item in os.listdir(zip_folder):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b366ba",
   "metadata": {},
   "source": [
    "## 文件夹结构与处理流程说明\n",
    "\n",
    "本项目的数据处理涉及以下文件夹：\n",
    "\n",
    "- **data_raw_zip**：存放从 CSMAR 下载的原始数据（.zip 压缩包），每个压缩包解压后会生成同名文件夹。\n",
    "- **data_raw**：存放解压后的原始数据文件。\n",
    "- **data_clean**：存放清洗后的数据文件。\n",
    "\n",
    "### 处理流程\n",
    "\n",
    "1. 列出 `data_raw_zip` 文件夹中的所有压缩文件。\n",
    "2. 将每个压缩包解压到 `data_raw` 文件夹下，解压后以压缩包同名文件夹存放。\n",
    "3. 为便于后续批量处理，对解压后的文件进行统一重命名。\n",
    "4. 编写函数，实现指定文件夹下文件的批量读取。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a7f774",
   "metadata": {},
   "source": [
    "## 解压 zip 文件到指定文件夹\n",
    "\n",
    "::: {.callout-tip}\n",
    "### 提示词\n",
    "\n",
    "- 将当前路径下的 'data_raw_zip' 文件夹中的所有 zip 文件解压到 'data_raw' 文件夹中。\n",
    "- 如果 'data_raw' 文件夹不存在，则创建该文件夹。\n",
    "- 每个 zip 文件解压后生成一个文件夹，文件夹名称与 zip 文件名相同，若有同名文件则覆盖之。\n",
    "  \n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8535a19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已解压: D:\\Github\\ds_data\\data\\CSMAR\\data_raw_zip\\CSMAR常用变量-2000-2024.zip -> D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\CSMAR常用变量-2000-2024\n",
      "已解压: D:\\Github\\ds_data\\data\\CSMAR\\data_raw_zip\\上市公司基本信息变更表2000-2024.zip -> D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\上市公司基本信息变更表2000-2024\n",
      "已解压: D:\\Github\\ds_data\\data\\CSMAR\\data_raw_zip\\上市公司基本信息年度表.zip -> D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\上市公司基本信息年度表\n",
      "已解压: D:\\Github\\ds_data\\data\\CSMAR\\data_raw_zip\\利润表-现金流量表-2000-2010.zip -> D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\利润表-现金流量表-2000-2010\n",
      "已解压: D:\\Github\\ds_data\\data\\CSMAR\\data_raw_zip\\利润表-现金流量表-2011-2024.zip -> D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\利润表-现金流量表-2011-2024\n",
      "已解压: D:\\Github\\ds_data\\data\\CSMAR\\data_raw_zip\\资产负债表-2000-2010.zip -> D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\资产负债表-2000-2010\n",
      "已解压: D:\\Github\\ds_data\\data\\CSMAR\\data_raw_zip\\资产负债表-2011-2024.zip -> D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\资产负债表-2011-2024\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "# 创建 'data_raw' 文件夹（如果不存在）\n",
    "if not os.path.exists(extract_folder):\n",
    "    os.makedirs(extract_folder)\n",
    "\n",
    "# 遍历 'data_raw_zip' 文件夹中的所有 zip 文件\n",
    "for item in os.listdir(zip_folder):\n",
    "    if item.endswith('.zip'):\n",
    "        zip_path = os.path.join(zip_folder, item)\n",
    "        folder_name = os.path.splitext(item)[0]\n",
    "        target_dir = os.path.join(extract_folder, folder_name)\n",
    "        # 如果目标文件夹已存在，则先删除\n",
    "        if os.path.exists(target_dir):\n",
    "            shutil.rmtree(target_dir)\n",
    "        # 解压 zip 文件到目标文件夹\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(target_dir)\n",
    "        print(f\"已解压: {zip_path} -> {target_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5ea9a2",
   "metadata": {},
   "source": [
    "## 更改部分文件夹中的文件名\n",
    "\n",
    "### 问题说明\n",
    "\n",
    "在 `data_raw` 文件夹中，有些子文件夹中的文件名是由 CSMAR 自动生成的，没有实际意义。为了便于后续处理，需要将这些文件名更改为更有意义的名称。\n",
    "\n",
    "此处以 `data_raw/资产负债表-??` 文件夹为例，可以看出，`资产负债表-2000-2010` 和 `资产负债表-2011-2024` 这两个文件夹中包含的文件名完全相同，这会导致随后纵向合并时难以区分数据来源。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a410430c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-- 资产负债表-2000-2010\n",
      "    |-- 版权声明.pdf\n",
      "    |-- 跨表查询_沪深京股票(年频).xlsx\n",
      "    |-- 跨表查询_沪深京股票(年频)[DES][.xlsx].txt\n",
      "|-- 资产负债表-2011-2024\n",
      "    |-- 版权声明.pdf\n",
      "    |-- 跨表查询_沪深京股票(年频).xlsx\n",
      "    |-- 跨表查询_沪深京股票(年频)[DES][.xlsx].txt\n"
     ]
    }
   ],
   "source": [
    "# 提示词：列出 `data_raw` 文件夹中包含关键词 {'资产负债表'} 的子文件夹的 file tree。\n",
    "\n",
    "keywords = '资产负债表'\n",
    "\n",
    "def print_keyword_file_tree(root, keyword, indent=\"\"):\n",
    "    for item in os.listdir(root):\n",
    "        item_path = os.path.join(root, item)\n",
    "        if os.path.isdir(item_path) and keyword in item:\n",
    "            print(indent + \"|-- \" + item)\n",
    "            for subitem in os.listdir(item_path):\n",
    "                print(indent + \"    |-- \" + subitem)\n",
    "\n",
    "print_keyword_file_tree(extract_folder, keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9c1aa8",
   "metadata": {},
   "source": [
    "\n",
    "查看后，发现子文件夹 `利润表-现金流量表-??` 和 `CSMAR常用变量-2000-2024` 中的文件名也存在类似问题。\n",
    "\n",
    "处理思路是：用文件夹名称作为该文件夹下的文件的文件名。因此，我们可以使用如下提示词生成处理代码：\n",
    "\n",
    "::: {.callout-tip}\n",
    "### 提示词\n",
    "\n",
    "1. 目的：更改 'data_raw' 文件夹中部分子文件夹中的文件的名称。\n",
    "2. 子文件夹名称为 'sub_folder_name'，其内部包含的文件记为 {Files} \n",
    "3. 如果 'sub_folder_name' 中包含关键词 {'常用变量', '资产负债表', '利润表'}，则把 {Files} 中的 '.xlsx' 和 '.txt' 文件的名称改为 'folder_name.xlsx' 和 'folder_name_DES.txt'。\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "82bbbc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "重命名: D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\CSMAR常用变量-2000-2024\\常用变量查询（年度）.xlsx -> D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\CSMAR常用变量-2000-2024\\CSMAR常用变量-2000-2024.xlsx\n",
      "重命名: D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\CSMAR常用变量-2000-2024\\常用变量查询（年度）[DES][xlsx].txt -> D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\CSMAR常用变量-2000-2024\\CSMAR常用变量-2000-2024_DES.txt\n",
      "重命名: D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\利润表-现金流量表-2000-2010\\跨表查询_沪深京股票(年频).xlsx -> D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\利润表-现金流量表-2000-2010\\利润表-现金流量表-2000-2010.xlsx\n",
      "重命名: D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\利润表-现金流量表-2000-2010\\跨表查询_沪深京股票(年频)[DES][.xlsx].txt -> D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\利润表-现金流量表-2000-2010\\利润表-现金流量表-2000-2010_DES.txt\n",
      "重命名: D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\利润表-现金流量表-2011-2024\\跨表查询_沪深京股票(年频).xlsx -> D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\利润表-现金流量表-2011-2024\\利润表-现金流量表-2011-2024.xlsx\n",
      "重命名: D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\利润表-现金流量表-2011-2024\\跨表查询_沪深京股票(年频)[DES][.xlsx].txt -> D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\利润表-现金流量表-2011-2024\\利润表-现金流量表-2011-2024_DES.txt\n",
      "重命名: D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\资产负债表-2000-2010\\跨表查询_沪深京股票(年频).xlsx -> D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\资产负债表-2000-2010\\资产负债表-2000-2010.xlsx\n",
      "重命名: D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\资产负债表-2000-2010\\跨表查询_沪深京股票(年频)[DES][.xlsx].txt -> D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\资产负债表-2000-2010\\资产负债表-2000-2010_DES.txt\n",
      "重命名: D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\资产负债表-2011-2024\\跨表查询_沪深京股票(年频).xlsx -> D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\资产负债表-2011-2024\\资产负债表-2011-2024.xlsx\n",
      "重命名: D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\资产负债表-2011-2024\\跨表查询_沪深京股票(年频)[DES][.xlsx].txt -> D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\资产负债表-2011-2024\\资产负债表-2011-2024_DES.txt\n"
     ]
    }
   ],
   "source": [
    "# 增加关键词 '常用变量'\n",
    "keywords = ['常用变量', '资产负债表', '利润表']\n",
    "\n",
    "# 检查并重命名文件\n",
    "for subfolder in os.listdir(extract_folder):\n",
    "    subfolder_path = os.path.join(extract_folder, subfolder)\n",
    "    if os.path.isdir(subfolder_path) and any(kw in subfolder for kw in keywords):\n",
    "        for file in os.listdir(subfolder_path):\n",
    "            file_path = os.path.join(subfolder_path, file)\n",
    "            if file.endswith('.xlsx'):\n",
    "                new_name = f\"{subfolder}.xlsx\"\n",
    "                new_path = os.path.join(subfolder_path, new_name)\n",
    "                os.rename(file_path, new_path)\n",
    "                print(f\"重命名: {file_path} -> {new_path}\")\n",
    "            elif file.endswith('.txt'):\n",
    "                new_name = f\"{subfolder}_DES.txt\"\n",
    "                new_path = os.path.join(subfolder_path, new_name)\n",
    "                os.rename(file_path, new_path)\n",
    "                print(f\"重命名: {file_path} -> {new_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec0138",
   "metadata": {},
   "source": [
    "### 查看处理后的文件名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c7ce5582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-- 资产负债表-2000-2010\n",
      "    |-- 版权声明.pdf\n",
      "    |-- 资产负债表-2000-2010.xlsx\n",
      "    |-- 资产负债表-2000-2010_DES.txt\n",
      "|-- 资产负债表-2011-2024\n",
      "    |-- 版权声明.pdf\n",
      "    |-- 资产负债表-2011-2024.xlsx\n",
      "    |-- 资产负债表-2011-2024_DES.txt\n"
     ]
    }
   ],
   "source": [
    "# 提示词：列出 `data_raw` 文件夹中包含关键词 {'资产负债表'} 的子文件夹的 file tree。\n",
    "\n",
    "keyword = '资产负债表'\n",
    "\n",
    "def print_keyword_file_tree(root, keyword, indent=\"\"):\n",
    "    for item in os.listdir(root):\n",
    "        item_path = os.path.join(root, item)\n",
    "        if os.path.isdir(item_path) and keyword in item:\n",
    "            print(indent + \"|-- \" + item)\n",
    "            for subitem in os.listdir(item_path):\n",
    "                print(indent + \"    |-- \" + subitem)\n",
    "\n",
    "print_keyword_file_tree(extract_folder, keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052c3038",
   "metadata": {},
   "source": [
    "## 列示 'data_raw' 文件夹中的 file tree\n",
    "\n",
    "::: {.callout-tip}\n",
    "### 提示词\n",
    "\n",
    "- 列示 'data_raw' 文件夹中的文件树结构。\n",
    "- 只列示文件夹名称和文件名称，不需要显示文件内容。\n",
    "- 如果文件夹中有子文件夹，则显示子文件夹名称。\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b66ad02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-- CSMAR常用变量-2000-2024\n",
      "    |-- CSMAR常用变量-2000-2024.xlsx\n",
      "    |-- CSMAR常用变量-2000-2024_DES.txt\n",
      "    |-- 版权声明.pdf\n",
      "|-- 上市公司基本信息变更表2000-2024\n",
      "    |-- STK_LISTEDCOINFOCHG.xlsx\n",
      "    |-- STK_LISTEDCOINFOCHG[DES][xlsx].txt\n",
      "    |-- 版权声明.pdf\n",
      "|-- 上市公司基本信息年度表\n",
      "    |-- STK_LISTEDCOINFOANL.xlsx\n",
      "    |-- STK_LISTEDCOINFOANL[DES][xlsx].txt\n",
      "    |-- 上市公司基本信息 数据库说明书.pdf\n",
      "|-- 利润表-现金流量表-2000-2010\n",
      "    |-- 利润表-现金流量表-2000-2010.xlsx\n",
      "    |-- 利润表-现金流量表-2000-2010_DES.txt\n",
      "    |-- 版权声明.pdf\n",
      "|-- 利润表-现金流量表-2011-2024\n",
      "    |-- 利润表-现金流量表-2011-2024.xlsx\n",
      "    |-- 利润表-现金流量表-2011-2024_DES.txt\n",
      "    |-- 版权声明.pdf\n",
      "|-- 资产负债表-2000-2010\n",
      "    |-- 版权声明.pdf\n",
      "    |-- 资产负债表-2000-2010.xlsx\n",
      "    |-- 资产负债表-2000-2010_DES.txt\n",
      "|-- 资产负债表-2011-2024\n",
      "    |-- 版权声明.pdf\n",
      "    |-- 资产负债表-2011-2024.xlsx\n",
      "    |-- 资产负债表-2011-2024_DES.txt\n"
     ]
    }
   ],
   "source": [
    "def print_file_tree(root, indent=\"\"):\n",
    "    for item in os.listdir(root):\n",
    "        item_path = os.path.join(root, item)\n",
    "        print(indent + \"|-- \" + item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print_file_tree(item_path, indent + \"    \")\n",
    "\n",
    "print_file_tree(extract_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99c0391",
   "metadata": {},
   "source": [
    "## 定义函数以批量读取指定文件夹下的文件\n",
    "\n",
    "### 文件内容分析\n",
    "\n",
    "观察后发现，每个文件夹下都包含两个文件：\n",
    "\n",
    "- `*.xlsx`：包含数据的 Excel 文件。\n",
    "- `*DES*.txt`：包含数据描述的文本文件。\n",
    "\n",
    "我们可以查看这两份文件的内容和结构，然后再决定读取方案。这里仍以 [资产负债表-2011-2024] 文件夹为例进行说明。\n",
    "\n",
    "**`资产负债表-2011-2024.xlsx`** 是数据文件，存储结构如下：前 6 列和前 9 行数据如下：\n",
    "\n",
    "<img style=\"width: 650px\" src=\"https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250526115914.png\">\n",
    "\n",
    "可以看出，从第 5 行开始是具体的观察值，而此前的四行则是表头信息：\n",
    "\n",
    "- 第一行是变量名\n",
    "- 第二行是变量的中文简称 (可以用作变量中文标签)\n",
    "- 第三行是变量的单位\n",
    "- 第四行是变量的其他说明信息。如第 5-6 列显示的是报表类型。\n",
    "\n",
    "`资产负债表-2011-2024_DES.txt` 是变量描述文件，主要包含变量的中文名称、单位、数据来源等信息。其原始内容如下：\n",
    "\n",
    "```raw\n",
    "-------------------- 资产负债表-2011-2024_DES.txt ---------begin--\n",
    "本信息:\n",
    "code[证券代码] - \n",
    "stknme[证券简称] - \n",
    "listingDate[上市日期] - \n",
    "EndDate[时间] - \n",
    "\n",
    "数据库名称：财务报表--> 表名称：资产负债表(FS_Combas)\n",
    "A001101000[货币资金] - 公司库存现金、银行结算户存款、……等的合计数。1990年起使用\n",
    "A001107000[交易性金融资产] - 交易性金融资产是……的债券投资、股票投资……。2007年起使用。\n",
    "……\n",
    "-------------------- 资产负债表-2011-2024_DES.txt ---------over--\n",
    "```\n",
    "\n",
    "可以看出，`资产负债表-2011-2024_DES.txt` 文件中每行的格式为：\n",
    "\n",
    "\n",
    "`varname`[**中文简称**] - *变量说明* \n",
    "\n",
    "- `varname` 是变量的英文名称。\n",
    "- `中文简称` 是变量的中文名称，可以作为变量标签。\n",
    "- `变量说明` 是对该变量的详细描述，包括变量的含义、计算方法、单位、数据来源等信息。\n",
    "\n",
    "\n",
    "对比这两份文件，有如下几种处理方案：\n",
    "\n",
    "**方案 1**：简化版\n",
    "\n",
    "如果只需要 `varname` 和 `中文简称` (后者可以作为前者的变量标签)，则处理过程为：\n",
    "\n",
    "**input**：`资产负债表-2011-2024.xlsx`  \n",
    "\n",
    "- 提取 `资产负债表-2011-2024.xlsx` 文件中第 5 行以后的所有数据，定义为数据框 `df`；\n",
    "- 提取 `资产负债表-2011-2024.xlsx` 前两行数据，定义为一个字典 **dict** - `{varname: 中文简称}`；\n",
    "- 将该字典附加到数据框 `df` 中，作为它的一个属性。\n",
    "\n",
    "**output**：`df` 数据框 + `dict` 字典。\n",
    "\n",
    "这种处理方式的好处是只需要数据文件 `资产负债表-2011-2024.xlsx`，缺陷是使用数据时，如果想知道每个变量详细信息，就需要翻阅 CSMAR 提供的 PDF 说明书，或 `资产负债表-2011-2024_DES.txt` 文件。\n",
    "\n",
    "**方案 2**：完整信息版\n",
    "\n",
    "此版本的思路是把变量的中文名和变量说明信息都提取出来，制作成两个字典，整合到数据框中。其好处是，我们可以随时在 Python 内部查看变量的中文名称和说明信息，而不需要翻阅 PDF 或其他文件。\n",
    "\n",
    "处理过程如下：\n",
    "\n",
    "**input**：`资产负债表-2011-2024.xlsx` + `资产负债表-2011-2024_DES.txt`\n",
    " \n",
    "- 提取 `资产负债表-2011-2024.xlsx` 文件中第 5 行以后的所有数据，定义为数据框 `df`；\n",
    "- 从 `资产负债表-2011-2024_DES.txt` 文件中提取信息，定义两个字典：\n",
    "  - 字典 1：`{varname: 中文简称}`，用于将英文变量名与其中文简称对应起来。\n",
    "  - 字典 2：`{varname: 变量说明}`，用于将英文变量名与其详细说明对应起来。\n",
    "- 将这两个字典附加到数据框 `df` 中，作为它的两个属性。\n",
    "\n",
    "**output**：`df` 数据框 + `dict1` 字典 + `dict2` 字典。\n",
    "\n",
    "\n",
    "**方案 3**：简化版-中文变量名\n",
    "\n",
    "如果已经对变量名有了充分了解，且只需要 `中文简称`，则处理过程为：\n",
    "\n",
    "**input**：`资产负债表-2011-2024.xlsx`\n",
    "\n",
    "- 读入 `资产负债表-2011-2024.xlsx` 文件中第 2 行以后的所有数据，定义为数据框 `df`；\n",
    "- 删除数据框 `df` 中的第 2-3 行；\n",
    "\n",
    "上述方案的对比：\n",
    "\n",
    "- **方案 1**：只保留英文变量名和中文简称，适用于对 CSMAR 数据库比较熟悉的用户。\n",
    "- **方案 2**：保留英文变量名、中文简称和变量说明，适用于需要详细了解变量含义的用户。\n",
    "- **方案 3**：只保留中文简称，变量含义直观明了。缺陷是，有些变量的中文简称中包含了 `(`，`（`，` ` 等特殊字符，需要额外转换。因此，不太推荐这种方式。\n",
    "\n",
    "下面，我们将实现方案 1 的处理过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcbe87e",
   "metadata": {},
   "source": [
    "### 方案 1：简化版处理代码\n",
    "\n",
    "处理思路：\n",
    "\n",
    "从 CSMAR 下载下来的每个 .zip 文件解压后，都会生成一个同名文件夹 (记为 `'folder_path'`)。该文件夹下包含一个 .xlsx 格式的数据文件和一个 .txt 格式的描述文件。因此，我们只需要指定 `'folder_path'`，便可以让 Python 根据文件后缀自动识别并读取这两个文件。对于 **方案 1**，我们只需要读取 .xlsx 文件，并将该文件的第二行作为变量 (第一行) 的中文标签即可。\n",
    "\n",
    "::: {.callout-tip}\n",
    "### 提示词\n",
    "\n",
    "- 目的：读取指定文件夹下的 Excel 文件，并将其第二行作为变量的中文标签。\n",
    "\n",
    "- input：folder = '资产负债表-2011-2024'\n",
    "  - folder_path = '{path}/data_raw/{folder}'\n",
    "  - {path} 已经在第一个 cell ('文件路径设定{tag}') 中定义\n",
    "\n",
    "- 处理思路：\n",
    "\n",
    "  - 检查该文件夹下以 `.xlsx` 结尾的文件的个数，如果大于 1 个，则报错。\n",
    "  - 读入该文件夹下以 `.xlsx` 结尾的文件。完整文件名为：`{filename}.xlsx`。\n",
    "  - 存入数据框 `df_filename`。\n",
    "    - 打印 forder_path 和 df_filename 的名称\n",
    "  - 删除 Excel 表格第 3 行和第 4 行\n",
    "  - 做一个字典：`dict_filename`，键为英文变量名，值为中文变量名。\n",
    "    - key: 英文变量名，从 Excel 第 1 行提取。\n",
    "    - value: 中文变量名，从 Excel 第 2 行提取。\n",
    "  - 将 `dict_filename` 附加到 `df_filename` 数据框中，作为它的一个属性。\n",
    "  - 删除第 2 行\n",
    "  \n",
    "- 显示处理后的数据框 `df_filename`.head() 的前 5 列和字典 `dict_filename` 的全部 {key: value}。\n",
    "  \n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aee7d13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder_path: d:\\Github\\ds_data\\data\\CSMAR\\data_raw\\资产负债表-2011-2024\n",
      "df_filename: 资产负债表-2011-2024.xlsx\n",
      " \n",
      "0  code  stknme listingDate  EndDate  FS_Combas-A001101000\n",
      "0     1    平安银行  1991-04-03     2011          0.000000e+00\n",
      "1     2     万科A  1991-01-29     2011          3.423951e+10\n",
      "2     3  PT 金田A  1991-07-03     2011                   NaN\n",
      "3     4  *ST 国华  1991-01-14     2011          5.712837e+07\n",
      "4     5   ST 星源  1990-12-10     2011          1.629275e+07\n",
      "code: 证券代码\n",
      "stknme: 证券简称\n",
      "listingDate: 上市日期\n",
      "EndDate: 时间\n",
      "FS_Combas-A001101000: 货币资金\n",
      "FS_Combas-A001107000: 交易性金融资产\n",
      "FS_Combas-A001109000: 短期投资净额\n",
      "FS_Combas-A001123000: 存货净额\n",
      "FS_Combas-A001100000: 流动资产合计\n",
      "FS_Combas-A001212000: 固定资产净额\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 构造文件夹路径\n",
    "folder = '资产负债表-2011-2024'\n",
    "folder_path = os.path.join(path, 'data_raw', folder)\n",
    "\n",
    "# 检查 .xlsx 文件数量，排除临时文件（如~$开头的文件）\n",
    "xlsx_files = [f for f in os.listdir(folder_path) if f.endswith('.xlsx') and not f.startswith('~$')]\n",
    "if len(xlsx_files) != 1:\n",
    "    raise ValueError(f\"{folder_path} 下存在 {len(xlsx_files)} 个有效 .xlsx 文件，请检查！\")\n",
    "xlsx_file = xlsx_files[0]\n",
    "xlsx_path = os.path.join(folder_path, xlsx_file)\n",
    "\n",
    "print(f\"folder_path: {folder_path}\")\n",
    "print(f\"df_filename: {xlsx_file}\")\n",
    "print(' ')\n",
    "\n",
    "# 读取前4行\n",
    "header = pd.read_excel(xlsx_path, nrows=4, header=None)\n",
    "\n",
    "# 删除第3、4行（索引2、3），再删除第2行（索引1），只保留第0行\n",
    "header_clean = header.drop([2, 3]).reset_index(drop=True)\n",
    "header_clean = header_clean.drop([1]).reset_index(drop=True)\n",
    "\n",
    "# 提取英文变量名和中文变量名\n",
    "en_names = header.iloc[0]\n",
    "cn_names = header.iloc[1]\n",
    "dict_filename = dict(zip(en_names, cn_names))\n",
    "\n",
    "# 读取数据，跳过前4行\n",
    "df_filename = pd.read_excel(xlsx_path, skiprows=4, header=None)\n",
    "df_filename.columns = en_names\n",
    "\n",
    "# 附加字典为属性\n",
    "df_filename.varname_cn = dict_filename\n",
    "\n",
    "# 显示前5列\n",
    "print(df_filename.iloc[:, :5].head())\n",
    "# 显示字典的前10个键值对\n",
    "for k, v in list(dict_filename.items())[:10]:\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2032ac36",
   "metadata": {},
   "source": [
    "### 优化代码\n",
    "\n",
    "上述代码可以一次性顺利执行，但耗时为 53s，太慢。于是，我把上述提示词和代码发给了 ChatGPT，请它优化代码。它给出的建议是：pandas 读取 `.xlsx` 格式本身就比较慢，尤其是数据量大或格式复杂时，速度瓶颈主要在于底层解析 Excel 文件的过程。此外，上述代码读取了两次 Excel 文件，第一次读取是为了获取变量名和中文简称，第二次读取是为了获取数据，这样会导致重复的 I/O 操作，进一步降低速度。\n",
    "\n",
    "应对方法是，先使用 **xlsx2csv** 包将 `.xlsx` 文件快速转换为 `.csv` 格式，然后再用 **pandas** 的 `read_csv` 读取数据，这样可以极大提升读取速度。\n",
    "\n",
    "优化后的代码只需 1-2 秒即可完成 ([ChatGPT 提示词](https://chatgpt.com/share/6834a1eb-b8fc-8005-a555-045a3986aeec))：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c304cb",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "### 提示词\n",
    "\n",
    "目标：定义一个函数 `read_files_in_folder(folder_path, Fname=None)`，用于批量读取指定文件夹下的 .xlsx 文件，并返回数据框和变量名-中文名字典。\n",
    "\n",
    "要求：\n",
    "\n",
    "1. 参数说明：\n",
    "    - `folder_path`：字符串，指定要读取的文件夹路径。\n",
    "    - `Fname`：字符串，可选，指定数据框和字典的名称前缀。若为 None，则自动取 .xlsx 文件名（不含扩展名），并将特殊字符替换为下划线。\n",
    "2. 处理流程：\n",
    "    - 检查文件夹下以 `.xlsx` 结尾且不以 `~$` 开头的文件，若数量不为 1，则报错。\n",
    "    - 将 .xlsx 文件转换为 .csv 文件（如已存在则跳过），转换时编码为 gbk。\n",
    "    - 读取 .csv 文件前 4 行，提取英文变量名和中文变量名。\n",
    "    - 对英文变量名，若为 'A-B' 结构，则只保留 B 部分。\n",
    "    - 构建 {英文变量名: 中文变量名} 的字典。\n",
    "    - 跳过前 4 行读取正文数据，列名用处理后的英文变量名。\n",
    "    - 返回一个 dict，包含数据框（键名为 `df_{Fname}`）和变量名字典（键名为 `dic_{Fname}`）。\n",
    "3. 代码需包含必要的 import，且不重复导入已在 notebook 其他 cell 导入的模块。\n",
    "4. 代码块必须完整、可直接运行。\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f36d92e1",
   "metadata": {
    "tags": [
     "read_xlsx_example"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------- 文件存储路径和文件名: --------------------\n",
      "folder_path: D:\\Github\\ds_data\\data\\CSMAR\\data_raw\\资产负债表-2011-2024\n",
      "df_filename: 资产负债表-2011-2024.xlsx\n",
      "\n",
      "     code  stknme listingDate EndDate FS_Combas-A001101000\n",
      "0  000001    平安银行  1991-04-03    2011                    0\n",
      "1  000002     万科A  1991-01-29    2011   34239514295.080002\n",
      "2  000003  PT 金田A  1991-07-03    2011                  NaN\n",
      "3  000004  *ST 国华  1991-01-14    2011      57128374.050000\n",
      "4  000005   ST 星源  1990-12-10    2011      16292748.160000\n",
      "\n",
      "\n",
      " -------------------- 变量名字典: --------------------\n",
      "code: 证券代码\n",
      "stknme: 证券简称\n",
      "listingDate: 上市日期\n",
      "EndDate: 时间\n",
      "FS_Combas-A001101000: 货币资金\n",
      "FS_Combas-A001107000: 交易性金融资产\n",
      "FS_Combas-A001109000: 短期投资净额\n",
      "FS_Combas-A001123000: 存货净额\n",
      "FS_Combas-A001100000: 流动资产合计\n",
      "FS_Combas-A001212000: 固定资产净额\n",
      "\n",
      "\n",
      " -------------------- 数据框维度: --------------------\n",
      "(81662, 32)\n"
     ]
    }
   ],
   "source": [
    "# {tag}: 'fcn_read_files_in_folder'\n",
    "#%pip install xlsx2csv\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from xlsx2csv import Xlsx2csv\n",
    "\n",
    "folder = '资产负债表-2011-2024'\n",
    "folder_path = os.path.join(path, 'data_raw', folder)\n",
    "# ========================================\n",
    "\n",
    "# 检查文件夹下 .xlsx 文件\n",
    "xlsx_files = [f for f in os.listdir(folder_path) if f.endswith('.xlsx') and not f.startswith('~$')]\n",
    "if len(xlsx_files) != 1:\n",
    "    raise ValueError(f\"{folder_path} 下存在 {len(xlsx_files)} 个有效 .xlsx 文件，请检查！\")\n",
    "xlsx_file = xlsx_files[0]\n",
    "xlsx_path = os.path.join(folder_path, xlsx_file)\n",
    "\n",
    "print('\\n', '-'*20, '文件存储路径和文件名:', '-'*20)\n",
    "print(f\"folder_path: {folder_path}\")\n",
    "print(f\"df_filename: {xlsx_file}\\n\")\n",
    "\n",
    "# 自动生成 CSV 文件名\n",
    "csv_path = xlsx_path.replace('.xlsx', '.csv')\n",
    "# 如已存在则跳过，否则转换\n",
    "if not os.path.exists(csv_path):\n",
    "    Xlsx2csv(xlsx_path, outputencoding=\"gbk\").convert(csv_path)\n",
    "\n",
    "# 读取前4行\n",
    "header = pd.read_csv(csv_path, nrows=4, header=None)\n",
    "\n",
    "# 提取变量名\n",
    "en_names = header.iloc[0].tolist()\n",
    "cn_names = header.iloc[1].tolist()\n",
    "dict_filename = dict(zip(en_names, cn_names))\n",
    "\n",
    "# 跳过前4行读取正文\n",
    "df_filename = pd.read_csv(\n",
    "    csv_path, skiprows=4, header=None, names=en_names, dtype=str\n",
    ")\n",
    "\n",
    "# 附加字典为属性\n",
    "setattr(df_filename, 'varname_cn', dict_filename)\n",
    "\n",
    "# 显示前5列\n",
    "print(df_filename.iloc[:, :5].head())\n",
    "print('\\n\\n', '-'*20, '变量名字典:', '-'*20)\n",
    "for k, v in list(dict_filename.items())[:10]:\n",
    "    print(f\"{k}: {v}\")\n",
    "print('\\n\\n', '-'*20, '数据框维度:', '-'*20)\n",
    "print(df_filename.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1660e913",
   "metadata": {},
   "source": [
    "## 定义函数以批量读取指定文件夹下的文件\n",
    "\n",
    "几个要点：\n",
    "\n",
    "- 这个提示词还需修改：目前的提示词不具有独立性，应该与上一个 Cell 的提示词合并。\n",
    "- 变量名的处理：在 '利润表-现金流量表xxx.csv' 和 '资产负债表xxx.csv' 文件中，变量名的格式为 'A-B'，我们需要删除 'A-' 部分，只保留 'C' 部分。\n",
    "  - `FS_Combas-A001101000: 货币资金` 变为 `A001101000: 货币资金`\n",
    "  - `FS_Comins-B003000000: 基本每股收益` 变为 `B003000000: 基本每股收益`\n",
    "  - `FS_Comscfd-C001021000: 支付的各项税费` 变为 `C001021000: 支付的各项税费`\n",
    "\n",
    "::: {.callout-tip}\n",
    "### 提示词\n",
    "\n",
    "- 以 {tag}: 'read_xlsx_example' Cell 中的代码为基础，定义一个函数 `read_files_in_folder(folder_path, Fname)`，用于批量读取指定文件夹下的所有文件。\n",
    "  - 函数参数 `folder_path` 是一个字符串，表示要读取的文件夹路径。\n",
    "  - `Fname` 是一个字符串，表示文件夹的名称，用于生成数据框和字典的名称。如果用户不指定，则默认使用 `.xlsx` 文件的名称，特殊字符采用 `_` 替换，确保符合 Python 命名规则。\n",
    "  - 如果变量名为 `A-B` 结构，则删除 'A-' 部分，只保留 'B' 部分。\n",
    "- 函数返回：一个数据框，名称为 `df_{Fname}`；一个字典，用于存储 {变量名: 变量中文简称}，名称为 `dic_{Fname}`。\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fb982647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from xlsx2csv import Xlsx2csv\n",
    "\n",
    "def read_files_in_folder(folder_path, Fname=None):\n",
    "    \"\"\"\n",
    "    批量读取指定文件夹下的 .xlsx 文件，返回数据框和变量名-中文名字典。\n",
    "    参数:\n",
    "        folder_path: 文件夹路径\n",
    "        Fname: 文件夹名称（可选），用于生成数据框和字典的名称。若为 None，则自动取 .xlsx 文件名（不含扩展名），并将特殊字符替换为下划线。\n",
    "    返回:\n",
    "        df_{Fname}: 数据框\n",
    "        dic_{Fname}: {英文变量名: 中文变量名} 字典\n",
    "    \"\"\"\n",
    "    # 查找 .xlsx 文件\n",
    "    xlsx_files = [f for f in os.listdir(folder_path) if f.endswith('.xlsx') and not f.startswith('~$')]\n",
    "    if len(xlsx_files) != 1:\n",
    "        raise ValueError(f\"{folder_path} 下存在 {len(xlsx_files)} 个有效 .xlsx 文件，请检查！\")\n",
    "    xlsx_file = xlsx_files[0]\n",
    "    xlsx_path = os.path.join(folder_path, xlsx_file)\n",
    "\n",
    "    # 自动生成 CSV 文件名\n",
    "    csv_path = xlsx_path.replace('.xlsx', '.csv')\n",
    "    if not os.path.exists(csv_path):\n",
    "        Xlsx2csv(xlsx_path, outputencoding=\"gbk\").convert(csv_path)  # 若使用 'utf-8' encoding，可能会导致中文乱码问题\n",
    "\n",
    "    # 读取前4行\n",
    "    header = pd.read_csv(csv_path, nrows=4, header=None)\n",
    "    en_names = header.iloc[0].tolist()\n",
    "    cn_names = header.iloc[1].tolist()\n",
    "\n",
    "    # 变量名处理：如果为 'A-B' 结构，则只保留 B 部分\n",
    "    def clean_varname(name):\n",
    "        if isinstance(name, str) and '-' in name:\n",
    "            parts = name.split('-')\n",
    "            if len(parts) >= 2:\n",
    "                return parts[-1]\n",
    "        return name\n",
    "\n",
    "    en_names_clean = [clean_varname(n) for n in en_names]\n",
    "    dic = dict(zip(en_names_clean, cn_names))\n",
    "\n",
    "    # 跳过前4行读取正文\n",
    "    df = pd.read_csv(csv_path, skiprows=4, header=None, names=en_names_clean, dtype=str)\n",
    "\n",
    "    # 生成 Fname\n",
    "    if Fname is None:\n",
    "        Fname = os.path.splitext(xlsx_file)[0]\n",
    "    Fname = re.sub(r'\\W+', '_', Fname)\n",
    "\n",
    "    # 返回带有指定名称的数据框和字典\n",
    "    return {f'df_{Fname}': df, f'dic_{Fname}': dic}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640918bb",
   "metadata": {},
   "source": [
    "## 批量处理\n",
    "\n",
    "接下来，我们就可以用上面定义的函数来批量处理 `data_raw` 文件夹中的所有子文件夹了。\n",
    "\n",
    "::: {.callout-tip}\n",
    "### 提示词\n",
    "\n",
    "用 {tag}: 'fcn_read_files_in_folder' Cell 中定义的 `read_files_in_folder()` 函数批量读取 `data_raw` 文件夹中的所有子文件夹下的文件，并将结果存储到 `data_clean` 文件夹中。主要步骤如下：\n",
    "\n",
    "- 如果 `data_clean` 文件夹不存在，则创建该文件夹；如果已经存在，则清空该文件夹中的所有内容。\n",
    "- 遍历 `data_raw` 文件夹中的所有子文件夹。\n",
    "  - 对于每个子文件夹，调用 `read_files_in_folder` 函数，读取其中的 `.xlsx` 文件和 `.txt` 文件。\n",
    "  - 将读取到的数据框和字典保存到 `data_clean` 文件夹中，文件名为 `{子文件夹名称}.pkl`。\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d51bf61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理 CSMAR常用变量-2000-2024 时出错: 'utf-8' codec can't decode byte 0xb9 in position 457: invalid start byte\n",
      "处理 上市公司基本信息变更表2000-2024 时出错: 'gbk' codec can't encode character '\\xa0' in position 93: illegal multibyte sequence\n",
      "处理 上市公司基本信息年度表 时出错: 'gbk' codec can't encode character '\\ufeff' in position 188: illegal multibyte sequence\n",
      "处理 利润表-现金流量表-2000-2010 时出错: 'utf-8' codec can't decode byte 0xb4 in position 728: invalid start byte\n",
      "处理 利润表-现金流量表-2011-2024 时出错: 'utf-8' codec can't decode byte 0xb4 in position 728: invalid start byte\n",
      "处理 资产负债表-2000-2010 时出错: 'utf-8' codec can't decode byte 0xb4 in position 624: invalid start byte\n",
      "处理 资产负债表-2011-2024 时出错: 'utf-8' codec can't decode byte 0xb4 in position 624: invalid start byte\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import pickle\n",
    "\n",
    "# 1. 如果 data_clean_folder 不存在则创建，已存在则清空\n",
    "if os.path.exists(data_clean_folder):\n",
    "    shutil.rmtree(data_clean_folder)\n",
    "os.makedirs(data_clean_folder)\n",
    "\n",
    "# 2. 遍历 data_raw 文件夹下所有子文件夹\n",
    "for subfolder in os.listdir(extract_folder):\n",
    "    subfolder_path = os.path.join(extract_folder, subfolder)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        try:\n",
    "            # 读取数据和变量名字典\n",
    "            result = read_files_in_folder(subfolder_path, Fname=subfolder)\n",
    "            # 统一保存为 {'df': df, 'varname_cn': dic}\n",
    "            df_key = [k for k in result if k.startswith('df_')][0]\n",
    "            dic_key = [k for k in result if k.startswith('dic_')][0]\n",
    "            save_dict = {'df': result[df_key], 'varname_cn': result[dic_key]}\n",
    "            # 保存为 pkl 文件\n",
    "            save_path = os.path.join(data_clean_folder, f\"{subfolder}.pkl\")\n",
    "            with open(save_path, 'wb') as f:\n",
    "                pickle.dump(save_dict, f)\n",
    "            print(f\"已保存: {save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"处理 {subfolder} 时出错: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f33f55",
   "metadata": {},
   "source": [
    "### 查看导入结果\n",
    "\n",
    "::: {.callout-tip}\n",
    "### 提示词\n",
    "\n",
    "列出 `data_clean` 文件夹中的所有文件，以及每个文件的对应字典的前五个 {key: value}\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2f0c490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>> 当前 data_clean 文件夹中的文件：\n",
      "\n",
      " ---------- CSMAR常用变量-2000-2024.pkl ----------\n",
      "数据框 shape: (61455, 33)\n",
      "前五行前五列：\n",
      "    Stkcd accper stknme AnaAttention       Audittyp\n",
      "0  000001   2001   平安银行          NaN        标准无保留意见\n",
      "1  000001   2002   平安银行     1.098612        标准无保留意见\n",
      "2  000001   2003   平安银行     1.386294        标准无保留意见\n",
      "3  000001   2004   平安银行     1.791759  带有解释性说明的无保留意见\n",
      "4  000001   2005   平安银行     1.791759        标准无保留意见\n",
      "前五个变量名-中文名：\n",
      "  Stkcd: 股票代码\n",
      "  accper: 会计年度\n",
      "  stknme: 股票简称\n",
      "  AnaAttention: 分析师关注度\n",
      "  Audittyp: 审计意见\n",
      "\n",
      " ---------- 上市公司基本信息变更表2000-2024.pkl ----------\n",
      "数据框 shape: (160275, 8)\n",
      "前五行前五列：\n",
      "   Symbol AnnouncementDate ImplementDate ChangedItem    SecurityID\n",
      "0  000001              NaN    1991-04-03        所属省份  201000000001\n",
      "1  000001              NaN    1991-04-03        注册地址  201000000001\n",
      "2  000001              NaN    1991-04-03        公司全称  201000000001\n",
      "3  000001              NaN    1991-04-03        证券简称  201000000001\n",
      "4  000001              NaN    1991-04-03      公司经营性质  201000000001\n",
      "前五个变量名-中文名：\n",
      "  Symbol: 股票代码\n",
      "  AnnouncementDate: 公告日期\n",
      "  ImplementDate: 实施日期\n",
      "  ChangedItem: 变更属性\n",
      "  SecurityID: 证券ID\n",
      "\n",
      " ---------- 上市公司基本信息年度表.pkl ----------\n",
      "数据框 shape: (64170, 40)\n",
      "前五行前五列：\n",
      "   Symbol ShortName     EndDate ListedCoID    SecurityID\n",
      "0  000001      深发展A  2001-12-31     101704  201000000001\n",
      "1  000001      深发展A  2002-12-31     101704  201000000001\n",
      "2  000001      深发展A  2003-12-31     101704  201000000001\n",
      "3  000001      深发展A  2004-12-31     101704  201000000001\n",
      "4  000001      深发展A  2005-12-31     101704  201000000001\n",
      "前五个变量名-中文名：\n",
      "  Symbol: 股票代码\n",
      "  ShortName: 股票简称\n",
      "  EndDate: 统计截止日期\n",
      "  ListedCoID: 上市公司ID\n",
      "  SecurityID: 证券ID\n",
      "\n",
      " ---------- 利润表-现金流量表-2000-2010.pkl ----------\n",
      "数据框 shape: (64163, 36)\n",
      "前五行前五列：\n",
      "     code  stknme listingDate EndDate         B001101000\n",
      "0  000001    平安银行  1991-04-03    2000                NaN\n",
      "1  000002     万科A  1991-01-29    2000  3783668674.180000\n",
      "2  000003  PT 金田A  1991-07-03    2000   464723527.060000\n",
      "3  000004  *ST 国华  1991-01-14    2000   131006632.910000\n",
      "4  000005   ST 星源  1990-12-10    2000   145947499.350000\n",
      "前五个变量名-中文名：\n",
      "  code: 证券代码\n",
      "  stknme: 证券简称\n",
      "  listingDate: 上市日期\n",
      "  EndDate: 时间\n",
      "  B001101000: 营业收入\n",
      "\n",
      " ---------- 利润表-现金流量表-2011-2024.pkl ----------\n",
      "数据框 shape: (81662, 36)\n",
      "前五行前五列：\n",
      "     code  stknme listingDate EndDate          B001101000\n",
      "0  000001    平安银行  1991-04-03    2011                 NaN\n",
      "1  000002     万科A  1991-01-29    2011  71782749800.679993\n",
      "2  000003  PT 金田A  1991-07-03    2011                 NaN\n",
      "3  000004  *ST 国华  1991-01-14    2011     74503718.530000\n",
      "4  000005   ST 星源  1990-12-10    2011     63534839.010000\n",
      "前五个变量名-中文名：\n",
      "  code: 证券代码\n",
      "  stknme: 证券简称\n",
      "  listingDate: 上市日期\n",
      "  EndDate: 时间\n",
      "  B001101000: 营业收入\n",
      "\n",
      " ---------- 资产负债表-2000-2010.pkl ----------\n",
      "数据框 shape: (64163, 32)\n",
      "前五行前五列：\n",
      "     code  stknme listingDate EndDate        A001101000\n",
      "0  000001    平安银行  1991-04-03    2000               NaN\n",
      "1  000002     万科A  1991-01-29    2000  995745160.050000\n",
      "2  000003  PT 金田A  1991-07-03    2000   58018167.850000\n",
      "3  000004  *ST 国华  1991-01-14    2000   64780229.730000\n",
      "4  000005   ST 星源  1990-12-10    2000   29118049.740000\n",
      "前五个变量名-中文名：\n",
      "  code: 证券代码\n",
      "  stknme: 证券简称\n",
      "  listingDate: 上市日期\n",
      "  EndDate: 时间\n",
      "  A001101000: 货币资金\n",
      "\n",
      " ---------- 资产负债表-2011-2024.pkl ----------\n",
      "数据框 shape: (81662, 32)\n",
      "前五行前五列：\n",
      "     code  stknme listingDate EndDate          A001101000\n",
      "0  000001    平安银行  1991-04-03    2011                   0\n",
      "1  000002     万科A  1991-01-29    2011  34239514295.080002\n",
      "2  000003  PT 金田A  1991-07-03    2011                 NaN\n",
      "3  000004  *ST 国华  1991-01-14    2011     57128374.050000\n",
      "4  000005   ST 星源  1990-12-10    2011     16292748.160000\n",
      "前五个变量名-中文名：\n",
      "  code: 证券代码\n",
      "  stknme: 证券简称\n",
      "  listingDate: 上市日期\n",
      "  EndDate: 时间\n",
      "  A001101000: 货币资金\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# 列出 data_clean 文件夹中每个文件的如下信息：\n",
    "#   - 文件名\n",
    "#   - 数据框的维度以及 '前五行+前五列'\n",
    "#   - 字典的前五个 {key: value} 对\n",
    "\n",
    "print(\"\\n>>>> 当前 data_clean 文件夹中的文件：\")\n",
    "for item in os.listdir(data_clean_folder):\n",
    "    if item.endswith('.pkl'):\n",
    "        print('\\n','-'*10, item, '-'*10)\n",
    "        with open(os.path.join(data_clean_folder, item), 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            if isinstance(data, dict) and 'df' in data and 'varname_cn' in data:\n",
    "                df = data['df']\n",
    "                var_dict = data['varname_cn']\n",
    "                print(f\"数据框 shape: {df.shape}\")\n",
    "                print(\"前五行前五列：\")\n",
    "                print(df.iloc[:5, :5])\n",
    "                print(\"前五个变量名-中文名：\")\n",
    "                for k, v in list(var_dict.items())[:5]:\n",
    "                    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00e2284",
   "metadata": {},
   "source": [
    "简要分析：\n",
    "\n",
    "考虑到随后要将这些文件合并为一个数据框，我们需要重点关注如下几点：\n",
    "\n",
    "- `上市公司基本信息变更表2000-2024.pkl` 暂时用不到，不予处理。\n",
    "- 哪些文件需要纵向合并 (append)?\n",
    "  - `利润表-现金流量表-xxx.pkl` 和 `资产负债表-xxx.pkl` 这两类文件需要纵向合并，分别存入数据框 `df_profit` 和 `df_asset` 中。\n",
    "- 哪些文件需要横向合并 (merge)?\n",
    "  - 将 `df_profit` 和 `df_asset` 横向合并为一个数据框 `df_financial`；\n",
    "  - 进而与 `CSMAR常用变量-2000-2024.pkl` 和 `上市公司基本信息年度表.pkl` 横向合并，得到最终的数据框 `df_final`。\n",
    "- 横向合并时，需要保证两份数据中有相同的变量名 (keys)。由于我们要合并的数据都是 'firm-year' 格式的面板数据，因此需要保证每个数据框中都有 'code' 和 'year' 这两个变量。\n",
    "  - 我们需要为 `CSMAR常用变量-2000-2024.pkl` 和 `上市公司基本信息年度表.pkl` 这两份文件添加 'code'  和 'year' 变量。二者分别对应这三个数据文件中的 `Symbol` 和 `EndDate` 变量。\n",
    "  - 对于 `利润表-现金流量表-xxx.pkl` 和 `资产负债表-xxx` 文件，需要将 `EndDate` 变量转换为 `year` 变量，以便后续合并。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7e4ef7",
   "metadata": {},
   "source": [
    "### 查看处理后的单个文件\n",
    "\n",
    "::: {.callout-tip}\n",
    "### 提示词\n",
    "\n",
    "- 列示 'CSMAR常用变量-2000-2024.pkl' 中的所有对象；\n",
    "- 空一行+分隔线；\n",
    "- 列示 'CSMAR常用变量-2000-2024.pkl' 的 shape；\n",
    "- 空一行+分隔线；\n",
    "- 列示 'CSMAR常用变量-2000-2024.pkl' 数据框中的 '前五行+前五列'；\n",
    "- 空一行+分隔线；\n",
    "- 列示字典中的所有 {变量名：中文简称}。\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06b16b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对象列表： ['df', 'varname_cn']\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "数据框 shape: (61455, 33)\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "    Stkcd accper stknme AnaAttention       Audittyp\n",
      "0  000001   2001   平安银行          NaN        标准无保留意见\n",
      "1  000001   2002   平安银行     1.098612        标准无保留意见\n",
      "2  000001   2003   平安银行     1.386294        标准无保留意见\n",
      "3  000001   2004   平安银行     1.791759  带有解释性说明的无保留意见\n",
      "4  000001   2005   平安银行     1.791759        标准无保留意见\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Stkcd: 股票代码\n",
      "accper: 会计年度\n",
      "stknme: 股票简称\n",
      "AnaAttention: 分析师关注度\n",
      "Audittyp: 审计意见\n",
      "InternationalBig4: 审计师是否来自国际四大\n",
      "Ysmvosd: 年个股流通市值\n",
      "Ysmvttl: 年个股总市值\n",
      "Yretwd: 考虑现金红利再投资的年个股回报率\n",
      "PropertyRightsNature: 产权性质\n",
      "Seperation: 两权分离度\n",
      "ActualControllerNatureID: 实际控制人性质编码\n",
      "OwnershipProportion: 实际控制人拥有上市公司所有权比例\n",
      "ControlProportion: 实际控制人拥有上市公司控制权比例\n",
      "Shrcr1: 股权集中度1\n",
      "Shrhfd5: 股权集中度9\n",
      "Shrz: 股权集中度5\n",
      "FundHoldProportion: 基金持股比例\n",
      "QFIIHoldProportion: 合格境外投资者持股比例\n",
      "BrokerHoldProportion: 券商持股比例\n",
      "BankHoldProportion: 银行持股比例\n",
      "NonFinanceHoldProportion: 非金融类上市公司持股比例\n",
      "InsInvestorProp: 机构投资者持股比例\n",
      "StaffNumber: 员工人数\n",
      "ConcurrentPosition: 两职合一\n",
      "Boardsize2: 董事会规模A\n",
      "ExecutivesNumber: 高管人数\n",
      "IndDirector: 独立董事人数\n",
      "SumSalary: 管理层薪酬\n",
      "TOP3SumSalary: 高管前三名薪酬总额\n",
      "Ynshrtrd: 年个股交易股数\n",
      "DirectorHoldshares: 董事会持股数量\n",
      "ManageHoldshares: 高级管理人员持股数量\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# 载入数据\n",
    "pkl_path = os.path.join(data_clean_folder, 'CSMAR常用变量-2000-2024.pkl')\n",
    "with open(pkl_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# 列示所有对象\n",
    "print(\"对象列表：\", list(data.keys()))\n",
    "\n",
    "print('\\n' + '-'*40 + '\\n')\n",
    "\n",
    "# 列示 shape\n",
    "df_csmar = data['df']\n",
    "print(\"数据框 shape:\", df_csmar.shape)\n",
    "\n",
    "print('\\n' + '-'*40 + '\\n')\n",
    "\n",
    "# 列示前五行前五列\n",
    "print(df_csmar.iloc[:5, :5])\n",
    "\n",
    "print('\\n' + '-'*40 + '\\n')\n",
    "\n",
    "# 列示字典中的所有 {变量名：中文简称}\n",
    "varname_cn_csmar = data['varname_cn']\n",
    "for k, v in varname_cn_csmar.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ac03bb",
   "metadata": {},
   "source": [
    "## 合并数据\n",
    "\n",
    "### 纵向合并\n",
    "\n",
    "::: {.callout-tip}\n",
    "### 提示词\n",
    "\n",
    "== 纵向合并不同年度的同名文件\n",
    "\n",
    "- 纵向合并 `data_clean` 文件夹中所有以 '资产负债表' 开头的文件。\n",
    "  - 将 `EndDate` 列重命名为 `year` 列。\n",
    "  - 合并后的数据框命名为 `df_assets`，并保存到 `data_clean` 文件夹中，文件名为 `df_assets.pkl`。\n",
    "- 纵向合并 `data_clean` 文件夹中所有以 '利润表' 开头的文件。\n",
    "  - 将 `EndDate` 列重命名为 `year` 列。\n",
    "  - 合并后的数据框命名为 `df_profit`，并保存到 `data_clean` 文件夹中，文件名为 `df_profit.pkl`。\n",
    "- 上述合并完成后，打印合并后的数据框的 shape；展示 '前三行 + 前五列'。\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8e1984d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_assets shape: (145825, 32)\n",
      "     code  stknme listingDate  year        A001101000\n",
      "0  000001    平安银行  1991-04-03  2000               NaN\n",
      "1  000002     万科A  1991-01-29  2000  995745160.050000\n",
      "2  000003  PT 金田A  1991-07-03  2000   58018167.850000\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "df_profit shape: (145825, 36)\n",
      "     code  stknme listingDate  year         B001101000\n",
      "0  000001    平安银行  1991-04-03  2000                NaN\n",
      "1  000002     万科A  1991-01-29  2000  3783668674.180000\n",
      "2  000003  PT 金田A  1991-07-03  2000   464723527.060000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# 合并资产负债表\n",
    "assets_dfs = []\n",
    "for item in os.listdir(data_clean_folder):\n",
    "    if item.startswith('资产负债表') and item.endswith('.pkl'):\n",
    "        with open(os.path.join(data_clean_folder, item), 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            df = data['df'] if isinstance(data, dict) and 'df' in data else data\n",
    "            if 'EndDate' in df.columns:\n",
    "                df = df.rename(columns={'EndDate': 'year'})\n",
    "            assets_dfs.append(df)\n",
    "if assets_dfs:\n",
    "    df_assets = pd.concat(assets_dfs, axis=0, ignore_index=True)\n",
    "    with open(os.path.join(data_clean_folder, 'df_assets.pkl'), 'wb') as f:\n",
    "        pickle.dump(df_assets, f)\n",
    "    print(\"df_assets shape:\", df_assets.shape)\n",
    "    print(df_assets.iloc[:3, :5])\n",
    "\n",
    "print('\\n' + '-'*40 + '\\n')\n",
    "\n",
    "# 合并利润表\n",
    "profit_dfs = []\n",
    "for item in os.listdir(data_clean_folder):\n",
    "    if item.startswith('利润表') and item.endswith('.pkl'):\n",
    "        with open(os.path.join(data_clean_folder, item), 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            df = data['df'] if isinstance(data, dict) and 'df' in data else data\n",
    "            if 'EndDate' in df.columns:\n",
    "                df = df.rename(columns={'EndDate': 'year'})\n",
    "            profit_dfs.append(df)\n",
    "if profit_dfs:\n",
    "    df_profit = pd.concat(profit_dfs, axis=0, ignore_index=True)\n",
    "    with open(os.path.join(data_clean_folder, 'df_profit.pkl'), 'wb') as f:\n",
    "        pickle.dump(df_profit, f)\n",
    "    print(\"df_profit shape:\", df_profit.shape)\n",
    "    print(df_profit.iloc[:3, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830ba8cf",
   "metadata": {},
   "source": [
    "### 横向合并\n",
    "\n",
    "::: {.callout-tip}\n",
    "### 提示词\n",
    "\n",
    "== 横向合并不同来源的数据\n",
    "\n",
    "1. 一些出现两次以上的功能，可以预先定义函数，确保代码结构清晰\n",
    "2. 资产负债表与利润表的合并\n",
    "  - 读入 `data_clean` 文件夹中的 `df_assets.pkl`。\n",
    "  - 按照关键词 '{code, year}' 与 `df_profit.pkl` 数据框横向合并；\n",
    "    - 如果有同名变量，则自动忽略。\n",
    "  - 合并后的数据存入数据框 `df_financial`;\n",
    "  - 数据框的前两列变量为 'code, year'\n",
    "3. 继续与 `上市公司基本信息年度表`, `CSMAR常用变量-2000-2024.pkl` 数据框横向合并。\n",
    "  - 合并前，先将 `上市公司基本信息年度表.pkl` 中的 `Symbol` 列重命名为 `code`，`EndDate` 列重命名为 `year`。\n",
    "  - 按照关键词 '{code, year}' 与 `df_financial` 数据框横向合并；\n",
    "    - 如果有同名变量，则自动忽略。\n",
    "4. 输出合并后的数据文件\n",
    "  - 合并后的数据存入数据框 `df_final`，\n",
    "    - 第一列为 'code'，第二列为 'year'，是两个独立的变量。\n",
    "    - 保存到 `data_clean` 文件夹中，文件名为 `df_final.pkl`。\n",
    "  - 最终数据框 `df_final` 的前两列变量为 'code, year'，并展示其 shape 和 '前三行 + 前五列'。\n",
    "5. 合并数据字典。将上述文件的字典合并为一个大字典 `dict_CSMAR`。\n",
    "  - 同名变量的中文简称和说明信息取先进入的文件的。 \n",
    "6. 打印数据字典尺寸，以及前十行信息，格式：{变量名: 中文简称}；\n",
    "7. 每组打印结果之间空一行，添加标题文字和分割线   \n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e3f08ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\Github\\\\ds_data\\\\data\\\\CSMAR\\\\data_clean\\\\df_assets.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m merged\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 1. 资产负债表与利润表的合并\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_clean_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_assets.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     16\u001b[0m     df_assets \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_clean_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_profit.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\Github\\\\ds_data\\\\data\\\\CSMAR\\\\data_clean\\\\df_assets.pkl'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# 工具函数：按 code, year 横向合并，自动忽略同名变量\n",
    "def merge_on_code_year(left, right, suffix='_right'):\n",
    "    # 只保留右表中不与左表重复的列\n",
    "    overlap = set(left.columns) & set(right.columns)\n",
    "    overlap -= {'code', 'year'}\n",
    "    right_use = right.drop(columns=list(overlap), errors='ignore')\n",
    "    merged = pd.merge(left, right_use, on=['code', 'year'], how='left', suffixes=('', suffix))\n",
    "    return merged\n",
    "\n",
    "# 1. 资产负债表与利润表的合并\n",
    "with open(os.path.join(data_clean_folder, 'df_assets.pkl'), 'rb') as f:\n",
    "    df_assets = pickle.load(f)\n",
    "with open(os.path.join(data_clean_folder, 'df_profit.pkl'), 'rb') as f:\n",
    "    df_profit = pickle.load(f)\n",
    "\n",
    "# 确保 'code' 和 'year' 列为字符串类型\n",
    "df_assets['code'] = df_assets['code'].astype(str)\n",
    "df_assets['year'] = df_assets['year'].astype(str)\n",
    "df_profit['code'] = df_profit['code'].astype(str)\n",
    "df_profit['year'] = df_profit['year'].astype(str)\n",
    "\n",
    "df_financial = merge_on_code_year(df_assets, df_profit, suffix='_profit')\n",
    "\n",
    "# 2. 继续与 “上市公司基本信息年度表” 和 “CSMAR常用变量-2000-2024.pkl” 合并\n",
    "with open(os.path.join(data_clean_folder, '上市公司基本信息年度表.pkl'), 'rb') as f:\n",
    "    data_basic = pickle.load(f)\n",
    "df_basic = data_basic['df'] if isinstance(data_basic, dict) and 'df' in data_basic else data_basic\n",
    "df_basic = df_basic.rename(columns={'Symbol': 'code', 'EndDate': 'year'})\n",
    "df_basic['code'] = df_basic['code'].astype(str)\n",
    "df_basic['year'] = df_basic['year'].astype(str)\n",
    "\n",
    "with open(os.path.join(data_clean_folder, 'CSMAR常用变量-2000-2024.pkl'), 'rb') as f:\n",
    "    data_csmar = pickle.load(f)\n",
    "df_csmar = data_csmar['df'] if isinstance(data_csmar, dict) and 'df' in data_csmar else data_csmar\n",
    "df_csmar['code'] = df_csmar['Stkcd'].astype(str)\n",
    "df_csmar['year'] = df_csmar['accper'].astype(str)\n",
    "\n",
    "df_financial = merge_on_code_year(df_financial, df_basic, suffix='_basic')\n",
    "df_final = merge_on_code_year(df_financial, df_csmar, suffix='_csmar')\n",
    "\n",
    "# 调整前两列顺序\n",
    "cols = list(df_final.columns)\n",
    "if 'code' in cols and 'year' in cols:\n",
    "    cols.remove('code')\n",
    "    cols.remove('year')\n",
    "    df_final = df_final[['code', 'year'] + cols]\n",
    "\n",
    "# 保存\n",
    "with open(os.path.join(data_clean_folder, 'df_final.pkl'), 'wb') as f:\n",
    "    pickle.dump(df_final, f)\n",
    "\n",
    "print(\"==== 合并后数据框 df_final ====\")\n",
    "print(\"df_final shape:\", df_final.shape)\n",
    "print(df_final.iloc[:3, :5])\n",
    "print('-'*40)\n",
    "\n",
    "# 4. 合并数据字典\n",
    "dicts = []\n",
    "# 资产负债表\n",
    "with open(os.path.join(data_clean_folder, '资产负债表-2011-2024.pkl'), 'rb') as f:\n",
    "    d = pickle.load(f)\n",
    "    if isinstance(d, dict) and 'varname_cn' in d:\n",
    "        dicts.append(d['varname_cn'])\n",
    "# 利润表\n",
    "for fname in ['利润表-现金流量表-2000-2010.pkl', '利润表-现金流量表-2011-2024.pkl']:\n",
    "    pkl_path = os.path.join(data_clean_folder, fname)\n",
    "    if os.path.exists(pkl_path):\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            d = pickle.load(f)\n",
    "            if isinstance(d, dict) and 'varname_cn' in d:\n",
    "                dicts.append(d['varname_cn'])\n",
    "# 基本信息\n",
    "if isinstance(data_basic, dict) and 'varname_cn' in data_basic:\n",
    "    dicts.append(data_basic['varname_cn'])\n",
    "# CSMAR常用变量\n",
    "if isinstance(data_csmar, dict) and 'varname_cn' in data_csmar:\n",
    "    dicts.append(data_csmar['varname_cn'])\n",
    "\n",
    "dict_CSMAR = {}\n",
    "for d in dicts:\n",
    "    dict_CSMAR.update(d)\n",
    "\n",
    "print(\"==== 合并后数据字典 dict_CSMAR ====\")\n",
    "print(f\"字典总变量数: {len(dict_CSMAR)}\")\n",
    "for i, (k, v) in enumerate(dict_CSMAR.items()):\n",
    "    print(f\"{k}: {v}\")\n",
    "    if i >= 200:\n",
    "        break\n",
    "print('-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1b6e42ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m numeric_cols \u001b[38;5;241m=\u001b[39m df_final\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mnumber])\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 统计量\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m desc \u001b[38;5;241m=\u001b[39m df_final[numeric_cols]\u001b[38;5;241m.\u001b[39magg([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m      9\u001b[0m desc \u001b[38;5;241m=\u001b[39m desc\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 缺失值统计\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10149\u001b[0m, in \u001b[0;36mDataFrame.aggregate\u001b[1;34m(self, func, axis, *args, **kwargs)\u001b[0m\n\u001b[0;32m  10146\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m  10148\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\u001b[38;5;28mself\u001b[39m, func\u001b[38;5;241m=\u001b[39mfunc, axis\u001b[38;5;241m=\u001b[39maxis, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m> 10149\u001b[0m result \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39magg()\n\u001b[0;32m  10150\u001b[0m result \u001b[38;5;241m=\u001b[39m reconstruct_and_relabel_result(result, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m  10151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:928\u001b[0m, in \u001b[0;36mFrameApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    926\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 928\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39magg()\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:193\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_dict_like()\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_list_like()\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n\u001b[0;32m    196\u001b[0m     f \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mget_cython_func(func)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:326\u001b[0m, in \u001b[0;36mApply.agg_list_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magg_list_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    319\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;124;03m    Compute aggregation in the case of a list-like argument.\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;124;03m    Result of aggregation.\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_or_apply_list_like(op_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:745\u001b[0m, in \u001b[0;36mNDFrameApply.agg_or_apply_list_like\u001b[1;34m(self, op_name)\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis other than 0 is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    744\u001b[0m keys, results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_list_like(op_name, obj, kwargs)\n\u001b[1;32m--> 745\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results_list_like(keys, results)\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:402\u001b[0m, in \u001b[0;36mApply.wrap_results_list_like\u001b[1;34m(self, keys, results)\u001b[0m\n\u001b[0;32m    399\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m concat(results, keys\u001b[38;5;241m=\u001b[39mkeys, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;66;03m# we are concatting non-NDFrame objects,\u001b[39;00m\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# e.g. a list of scalars\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Series\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    385\u001b[0m     ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[0;32m    386\u001b[0m     join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m    387\u001b[0m     keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[0;32m    388\u001b[0m     levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[0;32m    389\u001b[0m     names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m    390\u001b[0m     verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[0;32m    391\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_keys_and_objs(objs, keys)\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 只对数值型变量做统计\n",
    "numeric_cols = df_final.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# 统计量\n",
    "desc = df_final[numeric_cols].agg(['count', 'mean', 'std', 'min', 'max']).T\n",
    "desc = desc.rename(columns={'count': 'N', 'mean': 'Mean', 'std': 'SD', 'min': 'Min', 'max': 'Max'})\n",
    "\n",
    "# 缺失值统计\n",
    "missing = df_final.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "\n",
    "print(\"==== 数值型变量基本统计量 (N, Mean, SD, Min, Max) ====\")\n",
    "display(desc)\n",
    "\n",
    "print(\"\\n==== 各变量缺失值数量 (只显示有缺失的变量) ====\")\n",
    "display(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2c76fb38",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_53792\\2207892642.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "df_final.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76814c9f",
   "metadata": {},
   "source": [
    "### 输出最终数据文件\n",
    "\n",
    "::: {.callout-tip}\n",
    "### 提示词\n",
    "\n",
    "== 输出 csv 和 txt 文件到 [data_final] 文件夹\n",
    "\n",
    "1. 将 `df_final` 数据框保存为 `CSMAR_final.csv` 文件，存储在 [data_final] 文件夹中。\n",
    "2. 将 `dict_CSMAR` 字典保存为 `CSMAR_var_label.txt` 文件，存储在 [data_final] 文件夹中。每行格式为：`变量名: 中文简称`。\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8384fcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存数据文件: d:\\Github\\ds_data\\data\\CSMAR\\data_final\\CSMAR_final.csv\n",
      "已保存变量标签文件: d:\\Github\\ds_data\\data\\CSMAR\\data_final\\CSMAR_var_label.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 创建 data_final 文件夹（如果不存在）\n",
    "data_final_folder = os.path.join(path, 'data_final')\n",
    "if not os.path.exists(data_final_folder):\n",
    "    os.makedirs(data_final_folder)\n",
    "\n",
    "# 1. 保存 df_final 为 CSV\n",
    "csv_path = os.path.join(data_final_folder, 'CSMAR_final.csv')\n",
    "df_final.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"已保存数据文件: {csv_path}\")\n",
    "\n",
    "# 2. 保存 dict_CSMAR 为 txt\n",
    "txt_path = os.path.join(data_final_folder, 'CSMAR_var_label.txt')\n",
    "with open(txt_path, 'w', encoding='utf-8') as f:\n",
    "    for k, v in dict_CSMAR.items():\n",
    "        f.write(f\"{k}: {v}\\n\")\n",
    "print(f\"已保存变量标签文件: {txt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8c48ab",
   "metadata": {},
   "source": [
    "### 收尾：删除无用文件和过程文件\n",
    "\n",
    "> Note：这一步是可选的，主要是为了清理不必要的文件，以节省存储空间和提高数据处理效率。  \n",
    "> 建议：确认所有数据处理和合并工作完成后，再执行此步骤。\n",
    "\n",
    "有些过程文件已经不需要了：\n",
    "\n",
    "-  `data_raw` 文件夹中的 `.xlsx` 文件已经转换为 `.csv` 文件，因此可以删除。\n",
    "-  `data_clean` 文件夹中的一些文件也不需要了，如 `利润表-现金流量表-xxx.pkl` 和 `资产负债表-xxx.pkl`，因为它们已经被合并为 `df_financial.pkl`。\n",
    "\n",
    "\n",
    "::: {.callout-tip}\n",
    "### 提示词\n",
    "\n",
    "- 删除 `data_raw` 文件夹中所有子文件夹中的 `.xlsx` 文件。\n",
    "- 删除 `data_clean` 文件夹中如下文件：\n",
    "  - 以 `利润表-现金流量表-` 开头的文件；\n",
    "  - 以 `资产负债表-` 开头的文件；\n",
    "  \n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c53cf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 1. 删除 data_raw 文件夹中所有子文件夹中的 .xlsx 文件\n",
    "for subfolder in os.listdir(extract_folder):\n",
    "    subfolder_path = os.path.join(extract_folder, subfolder)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        for fname in os.listdir(subfolder_path):\n",
    "            if fname.endswith('.xlsx'):\n",
    "                file_path = os.path.join(subfolder_path, fname)\n",
    "                os.remove(file_path)\n",
    "                print(f\"已删除: {file_path}\")\n",
    "\n",
    "# 2. 删除 data_clean 文件夹中指定前缀的文件\n",
    "prefixes = ['利润表-现金流量表-', '资产负债表-']\n",
    "for fname in os.listdir(data_clean_folder):\n",
    "    if any(fname.startswith(prefix) for prefix in prefixes):\n",
    "        file_path = os.path.join(data_clean_folder, fname)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "            print(f\"已删除: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c2bcb2",
   "metadata": {},
   "source": [
    "### 呈现项目文档树\n",
    "\n",
    "要点：\n",
    "\n",
    "- 代码执行后会自动将工作目录切换回项目根目录，确保后续操作路径一致。\n",
    "\n",
    "::: {.callout-tip}\n",
    "### 提示词\n",
    "\n",
    "- 列示项目文档树结构。\n",
    "- 只列示文件夹名称和文件名称，不需要显示文件内容。\n",
    "- 如果文件夹中有子文件夹，则显示子文件夹名称。\n",
    "- 处理完后，将工作目录切换到项目根目录。\n",
    "- 为此代码块添加标题和合适的注释。\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a1e54ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 项目文档树结构 ===\n",
      "|-- 01_read_merge.ipynb\n",
      "|-- 02_data_clean.ipynb\n",
      "|-- CSMAR_API.md\n",
      "|-- CSMAR_firm_basic_infor.ipynb\n",
      "|-- data_clean\n",
      "    |-- CSMAR常用变量-2000-2024.pkl\n",
      "    |-- df_assets.pkl\n",
      "    |-- df_final.pkl\n",
      "    |-- df_profit.pkl\n",
      "    |-- 上市公司基本信息变更表2000-2024.pkl\n",
      "    |-- 上市公司基本信息年度表.pkl\n",
      "    |-- 利润表-现金流量表-2000-2010.pkl\n",
      "    |-- 利润表-现金流量表-2011-2024.pkl\n",
      "    |-- 资产负债表-2000-2010.pkl\n",
      "    |-- 资产负债表-2011-2024.pkl\n",
      "|-- data_final\n",
      "    |-- CSMAR_final.csv\n",
      "    |-- CSMAR_var_label.txt\n",
      "|-- data_raw\n",
      "    |-- CSMAR常用变量-2000-2024\n",
      "        |-- CSMAR常用变量-2000-2024.csv\n",
      "        |-- CSMAR常用变量-2000-2024.xlsx\n",
      "        |-- CSMAR常用变量-2000-2024_DES.txt\n",
      "        |-- 版权声明.pdf\n",
      "    |-- 上市公司基本信息变更表2000-2024\n",
      "        |-- STK_LISTEDCOINFOCHG.csv\n",
      "        |-- STK_LISTEDCOINFOCHG.xlsx\n",
      "        |-- STK_LISTEDCOINFOCHG[DES][xlsx].txt\n",
      "        |-- 版权声明.pdf\n",
      "    |-- 上市公司基本信息年度表\n",
      "        |-- STK_LISTEDCOINFOANL.csv\n",
      "        |-- STK_LISTEDCOINFOANL.xlsx\n",
      "        |-- STK_LISTEDCOINFOANL[DES][xlsx].txt\n",
      "        |-- 上市公司基本信息 数据库说明书.pdf\n",
      "    |-- 利润表-现金流量表-2000-2010\n",
      "        |-- 利润表-现金流量表-2000-2010.csv\n",
      "        |-- 利润表-现金流量表-2000-2010.xlsx\n",
      "        |-- 利润表-现金流量表-2000-2010_DES.txt\n",
      "        |-- 版权声明.pdf\n",
      "    |-- 利润表-现金流量表-2011-2024\n",
      "        |-- 利润表-现金流量表-2011-2024.csv\n",
      "        |-- 利润表-现金流量表-2011-2024.xlsx\n",
      "        |-- 利润表-现金流量表-2011-2024_DES.txt\n",
      "        |-- 版权声明.pdf\n",
      "    |-- 资产负债表-2000-2010\n",
      "        |-- 版权声明.pdf\n",
      "        |-- 资产负债表-2000-2010.csv\n",
      "        |-- 资产负债表-2000-2010.xlsx\n",
      "        |-- 资产负债表-2000-2010_DES.txt\n",
      "    |-- 资产负债表-2011-2024\n",
      "        |-- 版权声明.pdf\n",
      "        |-- 资产负债表-2011-2024.csv\n",
      "        |-- 资产负债表-2011-2024.xlsx\n",
      "        |-- 资产负债表-2011-2024_DES.txt\n",
      "|-- data_raw_zip\n",
      "    |-- CSMAR常用变量-2000-2024.zip\n",
      "    |-- 上市公司基本信息变更表2000-2024.zip\n",
      "    |-- 上市公司基本信息年度表.zip\n",
      "    |-- 利润表-现金流量表-2000-2010.zip\n",
      "    |-- 利润表-现金流量表-2011-2024.zip\n",
      "    |-- 资产负债表-2000-2010.zip\n",
      "    |-- 资产负债表-2011-2024.zip\n",
      "|-- functions\n",
      "    |-- CSMAR_var_label.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# === 项目文档树结构展示 ===\n",
    "# 本代码用于递归列示当前项目的文件夹和文件结构，便于快速了解项目目录布局。\n",
    "# 最后将工作目录切换回项目根目录。\n",
    "\n",
    "def print_project_tree(root, indent=\"\"):\n",
    "    for item in os.listdir(root):\n",
    "        item_path = os.path.join(root, item)\n",
    "        print(indent + \"|-- \" + item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print_project_tree(item_path, indent + \"    \")\n",
    "\n",
    "print(\"=== 项目文档树结构 ===\")\n",
    "print_project_tree(path)\n",
    "\n",
    "# 切换工作目录到项目根目录\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7953297",
   "metadata": {},
   "source": [
    "### 保留哪些文件夹？\n",
    "\n",
    "在本地运行完毕后，项目根目录下会包含如下文件夹：\n",
    "\n",
    "- [1] `data_raw_zip` 文件夹：**务必保留**，里面存放了从 CSMAR 下载的原始数据压缩包。\n",
    "- [2] `data_raw` 文件夹：**可以删除**，里面存放了解压后的 .xlsx 和 .txt 文档\n",
    "- [3] `data_clean` 文件夹：**酌情删除**，里面存放了清洗后的 `.pkl` 文件。\n",
    "- [4] `data_final` 文件夹：**建议保留**，里面存放了最终的 `.csv` 和 `.txt` 文件。\n",
    "\n",
    "可复现文档分享方案：\n",
    "\n",
    "一旦确定上述代码无误，在分享时，只需保留 `01_read_merge.ipynb` 文件和 `[data_raw_zip]` 文件夹即可。\n",
    "\n",
    "- 完整复现文档：\n",
    "  - `01_read_merge.ipynb` 文件：包含了从数据读取到合并的完整代码。\n",
    "  - `[data_raw_zip]` 文件夹：包含了从 CSMAR 下载的原始数据压缩包。\n",
    "- 直接使用最终文档 + 了解处理过程：\n",
    "  - `data_final` 文件夹：包含了最终的 `.csv` 和 `.txt` 文件，便于直接使用。\n",
    "  - `01_read_merge.ipynb` 文件：包含了从数据读取到合并的完整代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb030d44",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "## 下一步？\n",
    "\n",
    "接下来，我们会编写：\n",
    "\n",
    "-  `02_data_clean.ipynb` 文件，对 `data_final` 文件夹中的数据做进一步处理，包括：缺失值、文字变量转换为数值变量、生成新的变量、处理离群值等。\n",
    "-  `03_data_analysis.ipynb` 文件，对 `data_final` 文件夹中的数据进行分析，包括：描述性统计、相关性分析、回归分析等。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
